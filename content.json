{"meta":{"title":"iqhy's Blog","subtitle":null,"description":null,"author":"iqhy","url":"https://iqhy.github.io","root":"/"},"pages":[{"title":"","date":"2019-10-28T08:11:52.236Z","updated":"2019-10-28T08:11:52.236Z","comments":true,"path":"404.html","permalink":"https://iqhy.github.io/404.html","excerpt":"","text":"404 Page 404 找不到页面 返回上一页 返回首页"},{"title":"关于","date":"2020-02-28T03:11:20.000Z","updated":"2020-07-17T08:53:19.188Z","comments":false,"path":"about/index.html","permalink":"https://iqhy.github.io/about/index.html","excerpt":"","text":"Author: iqhy Disciplines: Communication Engineering University: Nanjing University of Science and Technology Github: https://github.com/iqhy Email: imyuhanqing@outlook.com"},{"title":"","date":"2019-10-28T08:09:04.522Z","updated":"2019-02-14T22:23:50.000Z","comments":true,"path":"404_css/style.css","permalink":"https://iqhy.github.io/404_css/style.css","excerpt":"","text":"body { background-color: #2F3242; } svg { position: absolute; top: 50%; left: 50%; margin-top: -250px; margin-left: -400px; } .message-box { height: 200px; width: 380px; position: absolute; top: 50%; left: 50%; margin-top: -100px; margin-left: 50px; color: #FFF; font-family: Roboto; font-weight: 300; } .message-box h1 { font-size: 60px; line-height: 46px; margin-bottom: 40px; } .buttons-con .action-link-wrap { margin-top: 40px; } .buttons-con .action-link-wrap a { background: #68c950; padding: 8px 25px; border-radius: 4px; color: #FFF; font-weight: bold; font-size: 14px; transition: all 0.3s linear; cursor: pointer; text-decoration: none; margin-right: 10px } .buttons-con .action-link-wrap a:hover { background: #5A5C6C; color: #fff; } #Polygon-1 , #Polygon-2 , #Polygon-3 , #Polygon-4 , #Polygon-4, #Polygon-5 { -webkit-animation: float 1s infinite ease-in-out alternate; animation: float 1s infinite ease-in-out alternate; } #Polygon-2 { -webkit-animation-delay: .2s; animation-delay: .2s; } #Polygon-3 { -webkit-animation-delay: .4s; animation-delay: .4s; } #Polygon-4 { -webkit-animation-delay: .6s; animation-delay: .6s; } #Polygon-5 { -webkit-animation-delay: .8s; animation-delay: .8s; } @-webkit-keyframes float { 100% { -webkit-transform: translateY(20px); transform: translateY(20px); } } @keyframes float { 100% { -webkit-transform: translateY(20px); transform: translateY(20px); } } @media (max-width: 450px) { svg { position: absolute; top: 50%; left: 50%; margin-top: -250px; margin-left: -190px; } .message-box { top: 50%; left: 50%; margin-top: -100px; margin-left: -190px; text-align: center; } }"},{"title":"文章分类","date":"2019-10-28T07:29:43.000Z","updated":"2020-02-28T06:04:21.234Z","comments":false,"path":"categories/index.html","permalink":"https://iqhy.github.io/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2019-10-24T15:22:28.000Z","updated":"2020-02-28T06:05:20.339Z","comments":false,"path":"tags/index.html","permalink":"https://iqhy.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"使用 Visual Studio 检测内存泄漏","slug":"使用 Visual Studio 检测内存泄漏","date":"2021-03-21T05:12:58.000Z","updated":"2021-03-24T09:14:00.649Z","comments":true,"path":"posts/2021/0321131258/","link":"","permalink":"https://iqhy.github.io/posts/2021/0321131258/","excerpt":"在 Visual Studio 中使用 C Run-time Library (CRT) 检测内存泄漏。","text":"在 Visual Studio 中使用 C Run-time Library (CRT) 检测内存泄漏。 内存泄漏是 C/C++ 中最难发现的 BUG 之一，通常难以被注意到，使用 Visual Studio 和 C Run-time Library (CRT) 可以帮助我们发现内存泄漏问题。 启用内存泄漏检测要启用内存泄漏检测，只需在你的程序前加上 123#define _CRTDBG_MAP_ALLOC#include &lt;stdlib.h&gt;#include &lt;crtdbg.h&gt; 其中，#define _CRTDBG_MAP_ALLOC 的作用是显示详细信息（如内存泄漏发生的文件、发生的具体行号），如果省略该语句，将不会输出详细信息。 #include crtdbg.h 将内存分配时使用的 malloc 和 free 函数分别改变为 _malloc_dbg 和 _free_dbg。在使用上，二者是相同的，后者只是比前者多了跟踪内存分配的功能，因此可以检测内存泄漏。 添加上述语句后，还需要在应用出口点前加上 _CrtDumpMemoryLeaks，以输出内存泄漏报告。 1_CrtDumpMemoryLeaks(); 例子现在来看一个简单的例子，编写如下程序： 123456789#define _CRTDBG_MAP_ALLOC#include &lt;stdlib.h&gt;#include &lt;crtdbg.h&gt;int main() &#123; int* var = new int[10]; _CrtDumpMemoryLeaks(); return 0;&#125; 注意要以调试模式运行该程序，如果不以调试模式运行则不会显示内存泄漏报告。 可以看到以下输出 12345Detected memory leaks!Dumping objects -&gt;&#123;105&#125; normal block at 0x00D68830, 40 bytes long. Data: &lt; &gt; CD CD CD CD CD CD CD CD CD CD CD CD CD CD CD CD Object dump complete. 可以看到，第一行 Detected memory leaks! 提示我们发现了内存泄漏。 {105} 是内存分配编号。 normal block 是类型，其他的类型还有 free, ignore 等，详细见参考资料。 0x00D68830 是内存泄漏的地址。 40 bytes 是内存泄漏的大小，因为我们分配了 10 个 int，正好是 40 bytes。 CD CD CD ... 是这块内存中的数据（十六进制表示）。 常见问题#define _CRTDBG_MAP_ALLOC 不输出详细信息可以观察到，虽然我们在代码中添加了 #define _CRTDBG_MAP_ALLOC，输出中仍然没有出现详细信息。如果没有显示代码的位置和行号，那么非常不利于我们调试代码。 解决方法是添加如下语句。 12345678910111213141516#define _CRTDBG_MAP_ALLOC#ifdef _DEBUG #define MYDEBUG_NEW new( _NORMAL_BLOCK, __FILE__, __LINE__) #define new MYDEBUG_NEW#else #define MYDEBUG_NEW#endif#include &lt;stdlib.h&gt;#include &lt;crtdbg.h&gt;int main() &#123; int* var = new int[10]; _CrtDumpMemoryLeaks(); return 0;&#125; 再次以调试模式运行该程序，发现正确输出了文件名和行号信息 12345Detected memory leaks!Dumping objects -&gt;C:\\path\\main.cpp(13) : &#123;105&#125; normal block at 0x009F8830, 40 bytes long. Data: &lt; &gt; CD CD CD CD CD CD CD CD CD CD CD CD CD CD CD CD Object dump complete. 可以看到内存泄漏发生在 main.cpp 的 13 行处。 使用 libeigen 时检测到内存泄漏在使用 Eigen 库时，会检测到内存泄漏，如下代码所示。 12345678910111213// 前面的重复代码省略#include &lt;iostream&gt;#include &lt;eigen3/Eigen/Dense&gt;int main()&#123; using RowMajorMat = Eigen::Matrix&lt;float, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor&gt;; RowMajorMat a(1024, 4096); RowMajorMat b(4096, 784); const auto c = a * b; std::cout &lt;&lt; c(0, 0) &lt;&lt; std::endl; _CrtDumpMemoryLeaks();&#125; 发现内存泄漏 1234567Detected memory leaks!Dumping objects -&gt;C:\\path\\eigen3\\Eigen\\src\\Core\\util\\Memory.h(88) : &#123;176&#125; normal block at 0x02446040, 12845072 bytes long. Data: &lt; @`D &gt; CD CD CD CD CD CD CD CD CD CD CD CD 40 60 44 02 C:\\path\\eigen3\\Eigen\\src\\Core\\util\\Memory.h(88) : &#123;175&#125; normal block at 0x01338040, 16777232 bytes long. Data: &lt; @ 3 &gt; CD CD CD CD CD CD CD CD CD CD CD CD 40 80 33 01 Object dump complete. 但是实际上并没有发生内存泄漏，这是由于变量 a, b, c 在执行 _CrtDumpMemoryLeaks 还没有被销毁。解决方法是加上一个大括号。 1234567891011int main()&#123; &#123; using RowMajorMat = Eigen::Matrix&lt;float, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor&gt;; RowMajorMat a(1024, 4096); RowMajorMat b(4096, 784); const auto c = a * b; std::cout &lt;&lt; c(0, 0) &lt;&lt; std::endl; &#125; _CrtDumpMemoryLeaks();&#125; 修改后未检测到内存泄漏。 参考资料","categories":[{"name":"C++","slug":"C","permalink":"https://iqhy.github.io/categories/C/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://iqhy.github.io/tags/C/"}]},{"title":"群晖安装 qBittorrent Enhanced Edition","slug":"群晖安装 qBittorrent Enhanced Edition","date":"2021-03-21T01:26:59.000Z","updated":"2021-03-21T03:30:06.009Z","comments":true,"path":"posts/2021/0321092659/","link":"","permalink":"https://iqhy.github.io/posts/2021/0321092659/","excerpt":"群晖安装 qbittorrentee。","text":"群晖安装 qbittorrentee。 安装 Docker安装 qbittorrentee 前，需要先到套件中心安装Docker。 在套件中心搜索 Docker，点击安装套件就可以了。 安装 qbittorrentee下载映像打开 Docker，点击左侧的注册表，在右侧的搜索框内搜索 qbittorrentee，选中 superng6/qbittorrentee，点击下载按钮，选择 latest 下载。 配置下载后，点击左侧的映像选项，可以看到它正在下载，等待其下载完成。 下载完成后，选中 superng6/qbittorrentee:latest 点击上方的启动，进行配置。 首先看到了常规设置的页面，这个页面没有要配置的东西，你可以将容器名称更改为你想要的名称，然后点击高级设置。 将几个页面配置如下： 高级设置页面 按需勾选启动自动重新启动（将会开机启动） 查看群晖的 IP 地址，例如我的是 192.168.1.111 勾选创建桌面快捷方式，选择网页，框内填入 http://192.168.1.111:8888（注意换成自己的 IP，:8888保留） 卷页面 打开 File Station，在 docker 文件夹内新建一个 qbittorrentee 文件夹 点击添加文件夹，将页面按下图配置，其中文件/文件夹对应的是群晖系统中真实的文件夹，装载路径对应的是 Docker 容器内部的文件夹。第二个文件夹是下载路径，选一个你想要的下载路径即可。 端口设置 直接按照下图设置即可 SSH 连接群晖 进行下一步配置前要使用 SSH 连接群晖，如果不会的话，可以参考下列步骤，会的可以跳到下一步。总体步骤为： 控制面板 &gt; 高级模式 &gt; 终端机和 SNMP &gt; cmd 打开控制面板 右上角点击基本模式，点击后将会切换到高级模式 打开终端机和 SNMP，勾选启用 SSH 功能，端口填 22，点击应用。 查看你的用户名（在控制面板 &gt; 用户账号中可以看到）。 打开 cmd，输入 ssh 用户名@192.168.1.111 -p 22 注意换成自己的 IP，按提示输入密码。 输入 id 用户名，回车。例如我的用户名是 admin，输入 id admin。记住 uid 和 gid 后面的数字。 环境 链接不需要配置，直接打开环境页面。 将 WEBUIPORT 的值修改为 8888，添加 PGID ，值为刚才记住的 gid 后面的值；添加 PUID, 值为 uid 后面的值。 点击应用、下一步，运行该容器。 打开 qibtorrentee现在桌面上应该出现了一个 qibtorrentee 的图标，打开它。你也可以在浏览器中访问 查看群晖的 IP 地址，例如我的是 192.168.1.111，和 地址:8888 直接打开。 默认的用户名为 admin，密码为 adminadmin，输入后就可以看到熟悉的界面了。 最后一步，点击工具 &gt; 选项 &gt; 连接将监听端口修改为 6991，安装完成。","categories":[{"name":"群晖","slug":"群晖","permalink":"https://iqhy.github.io/categories/%E7%BE%A4%E6%99%96/"}],"tags":[{"name":"群晖","slug":"群晖","permalink":"https://iqhy.github.io/tags/%E7%BE%A4%E6%99%96/"}]},{"title":"马尔可夫决策 MDP 基本概念 (二)","slug":"马尔可夫决策 MDP 基本概念 (二)","date":"2020-10-08T07:48:26.000Z","updated":"2020-10-08T12:54:03.200Z","comments":true,"path":"posts/2020/1008154826/","link":"","permalink":"https://iqhy.github.io/posts/2020/1008154826/","excerpt":"本文将介绍值函数 (Value function) 与马尔可夫决策过程(Markov Decision Processes, MDP)。","text":"本文将介绍值函数 (Value function) 与马尔可夫决策过程(Markov Decision Processes, MDP)。 上一节：马尔可夫决策 MDP 基本概念 (一) 前言上一节介绍了马尔可夫过程和马尔可夫奖励过程 (Markov Reward Processes, MRP)，这一节我们将介绍值函数 (Value function) 与马尔可夫决策过程。 值函数值函数 $v(s)$ 定义为回报 $G_t$ 的数学期望，即$$v(s)=\\mathbb{E}[G_t|S_t=s]$$$v(s)$ 的意义为从状态 $s$ 开始，获得的 $G_t$ 的数学期望。回顾一下，$G_t$ 的计算公式为$$G_t=R_{t+1}+\\gamma R_{t+2}+…=\\sum_{k=0}^{\\infty}{\\gamma ^kR_{t+k+1}}$$上一节中提到，某学生的学习过程可以有很多种，如下所示： C1 C2 C3 Pass Sleep，$G_1=-2.25$ C1 FB FB C1 C2 Sleep，$G_1=-3.125$ C1 C2 C3 Pub C2 C3 Pass Sleep，$G_1=-3.41$ C1 FB FB C1 C2 C3 Pub C1 … ，$G_1=-3.20$ … … 令 $\\gamma=\\frac{1}{2}$ ，可计算出每种学习过程的 $G_1$ 。理论上，根据 $v(s)$ 的定义，将所有 $G_1$ 求平均即可得到 $v(s)$。但实际上上述学习过程有无穷多个，因此需要采用其他方法计算 $v(s)$，该方法将在后面介绍。 马尔可夫决策过程简单回顾一下，马尔可夫过程建模了环境的变化，可以用数学语言描述该过程；为了让智能体从环境中学习又引入了奖励，有了马尔可夫奖励过程；而智能体需要与环境交互，在前面的模型中，再引入智能体对环境的影响，就有了马尔可夫决策过程，MDP。智能体对环境的影响就通过动作 $\\mathcal{A}$ 进行的。 定义马尔可夫决策过程是可以进行决策的马尔可夫奖励过程，用元组 $&lt;\\mathcal{S},\\mathcal{A},\\mathcal{P},\\mathcal{R},\\gamma&gt;$ 描述，其中 $\\mathcal{S}$ 是状态集合 $\\mathcal{A}$ 是动作集合 $\\mathcal{P}$ 是状态转移矩阵 (与之前稍有不同) $\\mathcal{R}$ 是奖励 (与之前稍有不同) $\\gamma$ 是折损因子 前面提到，MDP 与 MRP 的不同就是引入了 $\\mathcal{A}$，即智能体可以对环境产生影响。那么这个影响体现在哪里呢，就体现在 $\\mathcal{P}$ 和 $\\mathcal{R}$ 上。MDP 中的 $\\mathcal{P}$ 和 $\\mathcal{R}$ 不再只和状态有关，还和动作 $a\\in \\mathcal{A}$ 有关。智能体执行了不同的动作，会使环境的状态转移概率不同，也会收到不同的奖励值。 如下图所示，是一个描述学生学习的 MDP，其中的红色字体代表动作。现在，学生采取不同的动作，会进入不同的状态，也会获得不同的奖励。例如，在 Class 1 继续学习会获得 $-2$ 的奖励，并进入状态 Class 2；而在 Class 1 采取动作 Facebook 则会获得 $-1$ 的奖励，并进入状态 Facebook。采取同一动作也可能进入不同的状态，如在 Class 3 采取动作 Pub，则有 0.2 的概率进入 Class 1，0.4 的概率进入 Class 2，0.4 的概率进入 Class 3。 策略 (policy)MDP 中的一个重要概念是策略，一个策略 $\\pi$ 是关于状态的概率分布，定义为$$\\pi(a|s)=\\mathbb{P}{A_t=a|S_t=s}$$其意义为在状态 $s$ 采取每个动作的概率，有以下性质 一个策略完全定义了智能体的行为 MDP 中的策略完全取决于当前状态 策略与时间无关","categories":[{"name":"MDP","slug":"MDP","permalink":"https://iqhy.github.io/categories/MDP/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://iqhy.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"MDP","slug":"MDP","permalink":"https://iqhy.github.io/tags/MDP/"},{"name":"强化学习","slug":"强化学习","permalink":"https://iqhy.github.io/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"}]},{"title":"一个 Python 整数溢出的坑","slug":"一个 Python 整数溢出的坑","date":"2020-07-13T12:12:47.000Z","updated":"2020-07-13T12:23:03.821Z","comments":true,"path":"posts/2020/120390311/","link":"","permalink":"https://iqhy.github.io/posts/2020/120390311/","excerpt":"众所周知，Python 的整数是不会溢出的，例如运行如下代码，Python 可以完整地计算出 $2^{100}$","text":"众所周知，Python 的整数是不会溢出的，例如运行如下代码，Python 可以完整地计算出 $2^{100}$ 12print(2 ** 200)# 1606938044258990275541962092341162602522202993782792835301376 但是，在执行以下代码时，发现整数却溢出了 1234567891011import numpy as npresult = 0array = np.array([145, 124, 58])for i in array: result += i result = result &lt;&lt; 8print(result)# -1854129664 这是为什么呢？Python 的整数怎么会溢出呢？我们输出中间的计算过程 1234567891011121314151617181920import numpy as npresult = 0array = np.array([145, 124, 58])for i in array: result += i print(result) result = result &lt;&lt; 8 print(result, '\\n') # 输出结果:# 145# 37120 # # 37244# 9534464 # # 9534522# -1854129664 看来是在最后一步溢出的，难道是 Python 算错了吗？单独计算 12print(9534522 &lt;&lt; 8)# 2440837632 可以看到，单独计算 9534522 &lt;&lt; 8 的结果确是正确的。进一步调试，发现 result 的类型竟然是 int32 而不是 int 原来是因为 array 中的数据类型是 np.int32 ，因此变量 i 的类型也是 np.int32 ，在执行 result += i 后，int 类型与 np.int32 类型相加后结果被转成了 np.int32 这才出现了整数溢出。因此，只需将 i 的类型转为 int 就不会发生溢出了。修改前面的代码 1234567891011import numpy as npresult = 0array = np.array([145, 124, 58])for i in array: result += int(i) # 将 np.int32 转为 int result = result &lt;&lt; 8print(result)# 2440837632 没有出现溢出","categories":[{"name":"bug","slug":"bug","permalink":"https://iqhy.github.io/categories/bug/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://iqhy.github.io/tags/Python/"},{"name":"bug","slug":"bug","permalink":"https://iqhy.github.io/tags/bug/"}]},{"title":"马尔可夫决策 MDP 基本概念 (一)","slug":"马尔可夫决策 MDP 基本概念 (一)","date":"2020-06-19T15:24:37.000Z","updated":"2020-10-08T12:09:50.976Z","comments":true,"path":"posts/2020/0619232437/","link":"","permalink":"https://iqhy.github.io/posts/2020/0619232437/","excerpt":"本文将简要介绍马尔可夫过程 (Markov Processes) 与马尔可夫奖励过程 (Markov Reward Processes)。","text":"本文将简要介绍马尔可夫过程 (Markov Processes) 与马尔可夫奖励过程 (Markov Reward Processes)。 前言最近准备写一个系列，从马尔可夫决策过程(Markov Decision Processes, MDP) 到部分可观测马尔可夫决策过程 (Partially Observable Markov Decision Processes, POMDP), 再到分布式马尔可夫决策过程 (Decentralized Markov Decision Processes, Dec-MDP)。 要了解 MDP ，首先要了解马尔可夫过程 (Markov Processes)和马尔可夫奖励过程 (Markov Reward Processes)，这两者是 MDP 的基础。本文将按如下顺序介绍: 马尔可夫过程 (Markov Processes) 马尔可夫奖励过程 (Markov Reward Processes) 马尔可夫决策过程 (Markov Decision Processes) 马尔可夫过程 (Markov Processes)马尔可夫性质 (Markov Property)马尔可夫过程为什么叫这个名字呢，因为它具有马尔可夫性质。马尔可夫性质简而言之，就是未来发生的事情只与当前状态有关而与过去无关，是一个无记忆的过程，它要求状态包含可能对未来产生影响的所有信息。 举例说明，假设每天的天气有三种状态：晴天、阴天、下雨。我们将第 $i$ 天的状态记为 $S_i$ 。若第 7 天下雨，那么有$$S_7=下雨$$如果我们假设 $S_i$ 仅取决于 $S_{i-1}$ ，即第 $i$ 天的天气仅取决于第 $i-1$ 天的天气，这就满足马尔可夫性，用数学公式来描述就是$$\\mathbb{P}\\left[ S_{t+1}|S_t \\right] =\\mathbb{P}\\left[ S_{t+1}|S_t,S_{t-1},…,S_1 \\right]$$ 举例说明，若第 6 天天晴，则第七天有0.2的概率下雨；若第 6 天阴天，则第七天有0.3 的概率下雨；若第 6 天阴天，则第七天有 0.5 的概率下雨；第 7 天下雨的概率只与第 6 天的天气有关，而与前面 5 天的状态无关。 状态转移矩阵 (State Transition Matrix)很容易可以看出来，由于只有三种天气，前后两天的天气组合共有 $3\\times 3=9$ 种，那么总共就有 9 种天气变化的概率，它们叫作状态转移概率。将这 9 个概率按一定规则写进矩阵，就是状态转移矩阵。 那这个规则是怎样的呢？若我们将天晴、阴天、下雨这三种状态编号为 1、2、3，则状态转移矩阵中的第 $i$ 行，第 $j$ 列的元素意义如下$$P_{ij}=\\mathbb{P}\\left[ S_{t+1}=\\text{状态}i|S_t=\\text{状态}j \\right]$$换句话说，就是前一天天气为状态 $i$，后一天天气为状态 $j$ 的概率，按照这样的规则，整个状态转移矩阵 $P$ 为$$\\begin{matrix} &amp; \\text{to}\\newline P=\\text{from}&amp; \\left[ \\begin{matrix} P_{11}&amp; P_{12}&amp; P_{13}\\newline P_{21}&amp; P_{22}&amp; P_{23}\\newline P_{31}&amp; P_{32}&amp; P_{33}\\newline\\end{matrix} \\right]\\\\end{matrix}$$ 不难看出，状态转移矩阵 $P$ 每一行的和都为 1，因为概率之和必为 1。 马尔可夫过程的定义马尔可夫过程就是具有马尔可夫性的随机过程，上述天气的例子描述了一个满足马尔可夫性、随着时间的推移，天气不断随机变化的过程，这就是一个马尔可夫过程。马尔可夫过程用元组 $&lt;\\mathcal{S},\\mathcal{P}&gt;$ 描述。 $\\mathcal{S}$ 是所有状态的集合，在刚才的例子中 $\\mathcal{S}$ 就是三种不同的天气组成的集合 $\\mathcal{P}$ 是状态转移矩阵 例子将前面描述天气变化的马尔可夫过程画成图，如下图所示。马尔可夫过程都可以用这样的图来表示。 下面我们看另一个稍微复杂一点的例子，这是一个描述学生学习的马尔可夫过程。在这个例子中，学生共有三节课要学习，在上课过程中，学生有一定概率走神，去刷 Facebook或睡觉，也有可能去酒吧，还有可能坚持把三堂课学完，最终通过考试，按照同样的方法画成图，如下图所示。 将其状态转移概率写成状态转移矩阵，如该公式所示，可以看到，该矩阵的每行之和都是1。$$\\mathcal{P}=\\begin{matrix} &amp; \\begin{matrix} \\text{C}1&amp; \\text{C}2&amp; \\text{C}3&amp; \\text{Pass}&amp; \\text{Pub}&amp; \\text{FB}&amp; \\text{Sleep}\\newline\\end{matrix}\\newline \\begin{array}{l} \\text{C}1\\newline \\text{C}2\\newline \\text{C}3\\newline \\text{Pass}\\newline \\text{Pub}\\newline \\text{FB}\\newline \\text{Sleep}\\newline\\end{array}&amp; \\left[ \\begin{matrix} \\ \\ \\quad &amp; 0.5&amp; \\ \\ \\quad &amp; \\ \\ \\quad &amp; \\ \\ \\quad &amp; 0.5&amp; \\ \\ \\quad \\newline \\ \\ &amp; \\ \\ &amp; 0.8&amp; \\ \\ &amp; \\ \\ &amp; \\ \\ \\qquad&amp; 0.2\\newline \\ \\ &amp; \\ \\ &amp; \\ \\ &amp; 0.6&amp; 0.4&amp; \\ \\ &amp; \\ \\ \\newline \\ \\ &amp; \\ \\ &amp; \\ \\ &amp; \\ \\ &amp; \\ \\ &amp; \\ \\ &amp; 1.0\\newline 0.2&amp; 0.4&amp; 0.4&amp; \\ \\ &amp; \\ \\ &amp; \\ \\ &amp; \\ \\ \\newline 0.1&amp; \\ \\ &amp; \\ \\ &amp; \\ \\ &amp; \\ \\ &amp; 0.9&amp; \\ \\ \\newline \\ \\ &amp; \\ \\ &amp; \\ \\ &amp; \\ \\ &amp; \\ \\ &amp; \\ \\ &amp; 1.0\\newline\\end{matrix} \\right]\\\\end{matrix}$$与刚才天气的例子不同，这个马尔可夫过程有一个终止状态，一旦进入这个状态，整个过程就结束了，这个状态通常可能是游戏结束的状态。为了与其他普通状态一起表示，这个终止状态可以视为以概率 1 转移到自身，这样做的目的是方便处理。 马尔可夫奖励过程有奖励的马尔可夫过程就是马尔可夫奖励过程，为什么需要有奖励呢？ 马尔可夫过程仅仅对环境的变化进行了定义，而我们的最终目的通常是为了让智能体 (agent) 能够在环境中学习出好的策略，智能体怎么学习呢，靠的是奖励。若对我们有利，就给正奖励；若对我们不利，就给负奖励。 定义马尔可夫奖励过程是带奖励的马尔可夫过程，马尔可夫过程用元组 $&lt;\\mathcal{S},\\mathcal{P},\\mathcal{R},\\gamma&gt;$ 描述。 $\\mathcal{S}$ 是所有状态的集合 $\\mathcal{P}$ 是状态转移矩阵 $\\mathcal{R}$ 是奖励 $\\gamma$ 是折损因子 (discount factor)，$\\gamma \\in[0,1]$，这个后面解释，是用来选择“短视”或“远视”的。 例子上述学生学习的马尔可夫过程加上奖励后，如下图所示 学习的目的是为了通过考试，所以给予正奖励；而学习的过程中比较枯燥、辛苦，给负奖励；临时去酒吧能暂时感到快乐，给较小的正奖励。我们最终的目标是为了取得尽可能高的奖励。 若某学生的学习过程是 C1 C2 C3 Pass Sleep，那么在整个过程中获得的累计奖励是 4；若某学生的学习过程是 C1 FB FB C1 C2 Sleep，那么在整个过程中获得的累计奖励是 -8。 回报回报 (return) $G_t$ 定义为从时刻 $t$ 开始，之后获取的所有奖励乘上折损因子再求和，即$$G_t=R_{t+1}+\\gamma R_{t+2}+…=\\sum_{k=0}^{\\infty}{\\gamma ^kR_{t+k+1}}$$由于 $\\gamma \\in[0,1]$，$\\gamma$ 控制着对未来奖励的关心程度。若 $\\gamma=0$，$G_t$ 退化为 $G_t=R_{t+1}$ 意味着只考虑当前的奖励，不关心未来的奖励，最短视；相应地，若 $\\gamma=1$，意味着最远视。 $\\gamma$ 越接近 $0$ 则越短视 $\\gamma$ 越接近 $1$ 则越远视 为什么需要折损因子大多数 MRP 或 MDP 中都引入了折损因子，这是为什么呢？主要有以下几个方面的原因。 数学处理方便 防止回报 $G_t$ 趋于正无穷 模型与现实存在偏差，越远的未来可能偏差越大 在金融等领域有实际物理意义 与人类和动物的行为类似，人们更喜欢及时奖励 要注意的是回报 $G_t$ 与前面在整个过程中获得的累计奖励 $\\sum_{t=0}^{\\infty}{R_t}$ 是不同的，回报是站在当前的视角下考虑未来，因此需要乘上 $\\gamma$；在整个过程中获得的累计奖励，是结束后再统计获得的奖励，二者的时间节点是不同的。 总结马尔可夫过程就是满足马尔可夫性质的随机过程，为了让智能体在环境中学习，引入了奖励，这就是马尔可夫奖励过程。奖励分为即时奖励和未来奖励，折损因子 $\\gamma$ 用于平衡“短视”与“远视”。 参考资料 RL Course by David Silver 下一节：未完待续","categories":[{"name":"MDP","slug":"MDP","permalink":"https://iqhy.github.io/categories/MDP/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://iqhy.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"MDP","slug":"MDP","permalink":"https://iqhy.github.io/tags/MDP/"},{"name":"强化学习","slug":"强化学习","permalink":"https://iqhy.github.io/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"}]},{"title":"使用 Python 和 C++ 并行 MCTS","slug":"使用 Python 和 C++ 并行 MCTS","date":"2020-03-15T13:03:55.000Z","updated":"2020-03-15T15:47:02.573Z","comments":true,"path":"posts/2020/315210355/","link":"","permalink":"https://iqhy.github.io/posts/2020/315210355/","excerpt":"简单介绍在 Python 和 C++ 中蒙特卡洛树搜索 (MCTS) 的并行化方法。","text":"简单介绍在 Python 和 C++ 中蒙特卡洛树搜索 (MCTS) 的并行化方法。 前言当我们在 Python 中实现了 MCTS 后，可能会遇到性能问题，这时就需要将 MCTS 并行化。MCTS 的并行方法主要分为三种： 叶并行 (leaf parallelization), 即在叶节点扩展时进行并行。 根并行 (root parallelization), 即直接使用进程或线程创建多个不同的树，在不同的树中同时执行搜索。 树并行 (tree parallelization), 即多个线程在同一个树中进行并行，每个线程在树的不同部分执行搜索。 这些并行方法的详细介绍可以参考这篇论文的第 25 页。 图1 MCTS的并行化方法[1] 叶并行叶并行的方法比较简单，只需在遇到叶节点时，同时执行多次模拟 (simulation)，然后使用多次模拟的结果来代替之前的结果即可。但是在 AlphaZero 的算法中，叶并行的方法并不适用。因为该算法实际上并没有模拟 (simulation) 这个过程，而是使用神经网络直接返回当前节点的评估结果，因此需要使用其他并行方法。AlphaZero 的原理可以参考这篇文章。 根并行根并行的实现同样比较简单，只要使用 Multiprocessing 或 concurrent.futures.ProcessPoolExecutor 直接调用 MCTS 即可。 1234567891011121314import multiprocessing as mpdef mcts_main(a, b): ''' mcts搜索的主函数 输入参数：a, b ''' ...p = mp.Pool(10) # 10个进程 for i in range(50): # 50个待执行任务 p.apply_async(mcts_main, args=(a, b))p.close()p.join() 如果在 MCTS 中调用了 GPU 版的 Keras，需要设置显存按需增长，并且要将 import keras 放在函数内，否则将不能并行调用 model.predict() 123456789import tensorflow as tfconfig = tf.ConfigProto()config.gpu_options.allow_growth = Truesession = tf.Session(config=config)def mcts_main(a, b): import keras # import keras要放在函数内 # mcts搜索的主函数 ... 这样并行虽然简单，但缺点是程序占内存大，且显存容易不够用。 树并行在 Python 中直接按照上述方法并行后，可能还是无法满足需求，需要更高效的并行方法。由于 GIL 的限制，在Python 中不能使用多线程来并行 MCTS，但实现树并行时需要进程/线程间较多的通信，如果直接在 Python 中用 multiprocessing 实现，可能带来较大的性能损失，同时实现起来也比较困难[2]。 一种解决方法是用 C++ 实现树并行，再封装成 Python 接口，在 Python 中调用，这样就避开了 GIL 的限制。C++ 的树并行实现可以参考这个 Github 项目 。这个项目使用的是 PyTorch，如果你使用的是 Keras，要在 C++ 中调用 Keras 可以参考这篇文章。将 C++ 封装成 Python 接口可以参考这篇文章。 封装成 Python 接口后，由于避开了 GIL 的限制，可以直接通过多线程调用。 123456789101112131415import concurrent.futuresdef mcts_main(a, b): ''' mcts搜索的主函数 输入参数：a, b ''' ...# 最大线程数10，50个待执行任务with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor: futures = [executor.submit(mcts_main, a, b) for i in range(50)] for future in concurrent.futures.as_completed(futures): result = future.result() ... 参考资料[1] Browne, C. B., Powley, E., Whitehouse, D., Lucas, S. M., Cowling, P. I., Rohlfshagen, P., … &amp; Colton, S. (2012). A survey of monte carlo tree search methods. IEEE Transactions on Computational Intelligence and AI in games, 4(1), 1-43. [2] https://stackoverflow.com/questions/52584142/mcts-tree-parallelization-in-python-possible 本人水平有限，如有不足之处，欢迎指出。","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://iqhy.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://iqhy.github.io/tags/Python/"},{"name":"C++","slug":"C","permalink":"https://iqhy.github.io/tags/C/"},{"name":"mcts","slug":"mcts","permalink":"https://iqhy.github.io/tags/mcts/"},{"name":"Keras","slug":"Keras","permalink":"https://iqhy.github.io/tags/Keras/"}]},{"title":"在 C++ 中调用 keras","slug":"在 C++ 中调用 keras","date":"2020-02-29T08:18:32.000Z","updated":"2020-10-06T01:51:10.343Z","comments":true,"path":"posts/2020/0229161832/","link":"","permalink":"https://iqhy.github.io/posts/2020/0229161832/","excerpt":"使用 frugally-deep 在 C++ 中轻松调用 Keras 模型","text":"使用 frugally-deep 在 C++ 中轻松调用 Keras 模型 Keras 使用起来非常方便，我们有时候需要在 C++ 中调用训练好的模型，希望在 C++ 中调用 Keras 的 model.predict()，但 Keras 并没有提供 C++ API。一种解决方法是使用 TensorFlow 的 C++ API，但编译过程非常繁琐，容易失败。这里我们使用另一种方法，使用 Github 上的 frugally-deep。 介绍frugally-deep 是一个用 C++ 实现的库，它可以将 Keras 保存的 .h5 文件直接转为 C++ 中可调用的 .json 文件，经过一步转换后就可以直接调用。frugally-deep 使用起来比较简单，支持非常多常用的模型，无需编译 TensorFlow。同时它也是线程安全的，可以很方便的在多 CPU 上进行前向传播。另外，frugally-deep 不支持使用 GPU，如果不是必须要使用 GPU，frugally-deep 是一个很好的选择。 支持的模型frugally-deep 支持大多数常用的模型 Add, Concatenate, Subtract, Multiply, Average, Maximum AveragePooling1D/2D, GlobalAveragePooling1D/2D Bidirectional, TimeDistributed, GRU, LSTM, CuDNNGRU, CuDNNLSTM Conv1D/2D, SeparableConv2D, DepthwiseConv2D Cropping1D/2D, ZeroPadding1D/2D BatchNormalization, Dense, Flatten Dropout, AlphaDropout, GaussianDropout, GaussianNoise SpatialDropout1D, SpatialDropout2D, SpatialDropout3D MaxPooling1D/2D, GlobalMaxPooling1D/2D ELU, LeakyReLU, ReLU, SeLU, PReLU Sigmoid, Softmax, Softplus, Tanh UpSampling1D/2D Reshape, Permute Embedding 以及 multiple inputs and outputs nested models residual connections shared layers variable input shapes arbitrary complex model architectures / computational graphs custom layers (by passing custom factory functions to load_model) 安装frugally-deep 的安装很简单，可以使用官方安装教程 INSTALL.md 上的命令安装，也可以直接下载源码。使用命令安装的方法在官方的教程中已经很详细了，所以这里采用直接下载源码的方式。 使用 frugally-deep 前需要有 (截止2020年6月13日) 一个支持 C++14 的编译器 Python 版本在 3.7 或以上 TensorFlow 2.1.1 如果你正在使用 Tensorflow 1.x 的 Keras，安装 TensorFlow 2.x.x 后大多数情况下只需要把 import keras 修改为 import tensorflow.keras 即可，Keras 的改动并不大。 下载源码分别前往frugally-deep, FunctionalPlus , Eigen 和 json 点击右侧的 Code 再点击 Download ZIP 下载这些源码。(Gitlab 直接点击下载) 解压假设现在代码根目录下的源文件只有 main.cpp，文件结构为： 1+-- main.cpp 将 frugally-deep 源码中的 include 文件夹和 keras_export 文件夹解压到与 main.cpp 相同的目录下： 1234+-- include| +-- fdeep+-- keras_export+-- main.cpp 将 FunctionalPlus 源码中 include 文件夹内的 fplus 文件夹复制到 main.cpp 相同目录下的 include 文件夹内： 12345+-- include| +-- fdeep| +-- fplus+-- keras_export+-- main.cpp 同样，将 json 源码中 include 文件夹内的 nlohmann 文件夹复制到 main.cpp 相同目录下的 include 文件夹内： 123456+-- include| +-- fdeep| +-- fplus| +-- nolhmann+-- keras_export+-- main.cpp 最后将 eigen 源码中 Eigen 文件夹放在 main.cpp 相同目录下的 include 文件夹内 1234567+-- include| +-- Eigen| +-- fdeep| +-- fplus| +-- nolhmann+-- keras_export+-- main.cpp 需要的文件已经安装完成，下面可以开始使用了。 使用总的来说，使用 frugally-deep 的步骤为： 在 Python 中训练好模型后，使用 model.save(&#39;....h5&#39;, include_optimizer=False) 保存模型 使用 keras_export/convert_model.py 将 .h5 模型转换成 C++ 模型 在 C++ 中使用 fdeep::load_model(...) 加载模型 在 C++ 中使用 model.predict(...) 调用模型 下面我们以 frugally-deep 主页 上的例子来说明如何使用。假设我们在 Python 中编写了模型 12345678910111213141516# create_model.pyimport numpy as npfrom tensorflow.keras.layers import Input, Densefrom tensorflow.keras.models import Modelinputs = Input(shape=(4,))x = Dense(5, activation='relu')(inputs)predictions = Dense(3, activation='softmax')(x)model = Model(inputs=inputs, outputs=predictions)model.compile(loss='categorical_crossentropy', optimizer='nadam')model.fit( np.asarray([[1, 2, 3, 4], [2, 3, 4, 5]]), np.asarray([[1, 0, 0], [0, 0, 1]]), epochs=10)model.save('keras_model.h5', include_optimizer=False) 运行 create_model.py 后，当前目录下生成了 keras_model.h5，接下来使用下面的命令进行转换 1python keras_export/convert_model.py keras_model.h5 fdeep_model.json 看到下面这些就是转换成功了，转换成功后，当前目录下会生成 fdeep_model.json，在 C++ 中读取 fdeep_model.json 就可以直接调用了。 12345678910111213141516Forward pass took 0.091729 s.Forward pass took 0.038896 s.Forward pass took 0.077791 s.Starting performance measurements.Forward pass took 0.037899 s.Forward pass took 0.037896 s.Forward pass took 0.043883 s.Forward pass took 0.038922 s.Forward pass took 0.042861 s.Forward pass took 0.04029220000000001 s on average.Converting model architecture.Converting model weights.Done converting model weights.Calculating model hash.Model conversion finished.writing fdeep_model.json 转换过程中，frugally-deep 会自动对模型进行测试，验证相同的输入下 ，模型在 Python 和 C++ 中的输出是否相同。若输出不同会直接报错，所以不必担心转换出错。 转换完成后，在 C++ 中进行调用 12345678910// main.cpp#include &lt;fdeep/fdeep.hpp&gt;int main()&#123; const auto model = fdeep::load_model(\"fdeep_model.json\"); const auto result = model.predict( &#123;fdeep::tensor(fdeep::tensor_shape(static_cast&lt;std::size_t&gt;(4)), &#123;1, 2, 3, 4&#125;)&#125;); std::cout &lt;&lt; fdeep::show_tensors(result) &lt;&lt; std::endl;&#125; 这时，以 Visual Studio 为例，编译器会报错 1fatal error C1083: 无法打开包括文件: “fdeep/fdeep.hpp”: No such file or directory 这是因为还没有添加附加包含目录，右键点击“解决方案资源管理器”中的项目名称，选择属性 -&gt; 配置属性 -&gt; C/C++ -&gt; 常规，在右侧的附加包含目录中填上 $(ProjectDir)include; 若使用的是 gcc 编译器，要在编译时加上参数 -Iinclude 再次运行 main.cpp，输出： 12345Loading json ... done. elapsed time: 0.009921 sBuilding model ... done. elapsed time: 0.018725 sRunning test 1 of 1 ... done. elapsed time: 0.003242 sLoading, constructing, testing of fdeep_model.json took 0.038064 s overall.[[[[[[[0.7297, 0.1624, 0.1078]]]]]]] 成功输出了结果，调用成功。另外，model.predict() 是线程安全的，可以直接在多个线程中调用。如果想在多 CPU 上并行预测，使用 model::predict_multi 就会自动在多 CPU 上执行 model.predict()。要注意的是，model::predict_multi 的并行是对多个输入数据的并行，并不是对一个数据的并行。 常见问题model.predict() 的输入输出类型model.predict() 的输入类型是 fdeep::tensor，下面的例子说明了如何声明一个 fdeep::tensor 并初始化 12345678// 声明一个tensor，形状参数在fdeep::tensor_shape()中，0是初始化的值fdeep::tensor t(fdeep::tensor_shape(3, 1, 1), 0);// 对tensor赋值最简单的方法是使用t.set()t.set(fdeep::tensor_pos(0, 0, 0), 1);t.set(fdeep::tensor_pos(1, 0, 0), 2);t.set(fdeep::tensor_pos(2, 0, 0), 3);// 赋值后即可传入model.predict()const auto result = model.predict(t); 有了 fdeep::tensor 我们可能会需要将其转化为 std::vector 进行后续的操作 12// 将tensor转为std::vectorconst std::vector&lt;float&gt; vec = t.to_vector(); 需要注意的是，model.predict() 返回的类型是 fdeep::tensors 而不是fdeep::tensor。实际上 fdeep::tensors 是作者给 std::vector&lt;tensor&gt; 定义的别名，若想将其转为 vector，可使用 12// 将vector&lt;tensor&gt;中的第一个tensor转为vector&lt;float&gt;const auto result_vec = result.front().to_vector(); 除此之外，其他的方法可以参考官方 FAQ.md。要注意，frugally-deep 中必须采用 channel-last 的格式。 error C2653:使用 Visual Studio 2019 时可能会遇到这个问题 1error C2653: &apos;FOut&apos;: is not a class or namespace name 这是一个编译器 BUG，详见 Github issue ，微软官方称已经在 16.5 Preview 2 版本中修复，但是目前升级到最新版 16.6 后仍有很多人反应存在此问题，解决方法是使用 Visual Studio 2017 或 gcc 编译器。 fdeep::model 没有默认构造函数当使用 fdeep::model 作为类的成员变量时，会遇到 fdeep::model 没有默认构造函数 的问题，这是作者刻意为之的，解决方法是使用std::unique_ptr&lt;fdeep::model&gt; 下面的例子说明了如何使用 1234567891011121314// neural_network.h#pragma once#include &lt;fdeep/fdeep.hpp&gt;class NeuralNetwork&#123;private: std::unique_ptr&lt;fdeep::model&gt; model;public: NeuralNetwork(); fdeep::tensors predict(fdeep::tensor&amp; t);&#125;; 123456789101112// neural_network.cpp#include \"neural_network.h\"NeuralNetwork::NeuralNetwork()&#123; this-&gt;model = std::make_unique&lt;fdeep::model&gt;(fdeep::load_model(\"fdeep_model.json\"));&#125;fdeep::tensors NeuralNetwork::predict(fdeep::tensor&amp; t)&#123; return this-&gt;model-&gt;predict(&#123; t &#125;);&#125; 运行速度比 Python 慢 100 倍这是因为编译器没有开优化。若使用 Visual Studio ，要把”Debug”模式改为”Release”模式。 gcc 要开 -O3 优化。修改后就正常了。参考FAQ.md 总结如果你需要在 C++ 中调用 model.predict() 且没有使用 GPU 的需求，frugally-deep 是一个很好的选择。 还想了解更多可以阅读官方的英文资料 frugally-deep 参考资料 https://github.com/Dobiasd/frugally-deep","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://iqhy.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://iqhy.github.io/tags/C/"},{"name":"机器学习","slug":"机器学习","permalink":"https://iqhy.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"keras","slug":"keras","permalink":"https://iqhy.github.io/tags/keras/"}]},{"title":"Python 调用 C++","slug":"Python 调用 C++","date":"2020-02-28T07:56:01.000Z","updated":"2020-07-18T02:32:21.432Z","comments":true,"path":"posts/2020/0228155601/","link":"","permalink":"https://iqhy.github.io/posts/2020/0228155601/","excerpt":"Python 的代码优雅而实用，但是经常会遇到性能问题，这时可以使用 C/C++ 重写几个函数，然后再用 Python 调用，这样就同时兼顾了开发效率和性能。","text":"Python 的代码优雅而实用，但是经常会遇到性能问题，这时可以使用 C/C++ 重写几个函数，然后再用 Python 调用，这样就同时兼顾了开发效率和性能。 本文分为3个部分 安装 Cython (注意区别 CPython) Python 调用 C++ 函数 Python 调用 C++ 类 安装 Cython安装 Cython 最简单方法的是使用： pip install cython 或 conda install cython Python 的程序写完了可以直接通过 python main.py 执行，但与 Python 不同，Cython 编写的程序需要编译后才能执行，因此，Cython 要求系统中有 C/C++ 编译器，gcc/g++ 或是 Visual Studio 的编译器均可。若电脑中已经安装了 Visual Studio 的 C++ 相关工具，那么电脑中就已经有 Visual Studio 的 C++ 编译器了，Cython 可以直接使用它。 Python 调用 C/C++ 函数如果我们在 Python 中遇到了一个执行很慢的函数，需要用 C++ 重写这个函数，下面我们通过一个简单的例子来说明如何处理。 编写一个 Python 函数以一个简单的函数为例，在 Python 中编写如下函数来计算 $\\text{tanh}(x)$ 的值 1234567891011121314151617181920from random import randomfrom time import timee = 2.7182818284590452353602874713527def sinh(x): return (1 - (e ** (-2 * x))) / (2 * (e ** -x))def cosh(x): return (1 + (e ** (-2 * x))) / (2 * (e ** -x))def tanh(x): return sinh(x) / cosh(x)data = [random() for i in range(1000000)] # 生成随机数据start_time = time() # 调用1000000次tanh函数并统计时间result1 = list(map(tanh, data))end_time = time()print(end_time - start_time) 运行该程序需要 1.39 秒，接下来将上述函数改写成 C++，将其保存在 mytanh.cpp 中 123456789101112131415161718#include &lt;cmath&gt;const double e = 2.7182818284590452353602874713527; double mysinh(double x)&#123; return (1 - pow(e, (-2 * x))) / (2 * pow(e, -x));&#125;double mycosh(double x)&#123; return (1 + pow(e, (-2 * x))) / (2 * pow(e, -x));&#125;double mytanh(double x)&#123; return mysinh(x) / mycosh(x);&#125; 由于sinh, cosh, tanh是 C++ 库函数，为了避免命名冲突，这里修改一下函数名。 在 Cython 中声明该函数C++ 的函数已经重写好了，下面要将 .cpp 代码进行一些“包装”，使 Python 能够调用它。这个“包装”的工作就是通过 Cython 进行的，众所周知，C++ 是静态类型语言，Python 是动态类型语言，不做任何处理，二者将不能直接调用，“包装”的主要工作其实就是完成各个变量的“类型转换”，例如将 Python 的 int 对象转为 C++ 的 int 类型，这两种 int 是不同的。 Cython 使用后缀名为 .pyx 和 .pxd 的文件，它们也是代码文件。.pyx 类似于 .cpp，.pxd 类似于 .h。下面进行“包装工作”，我们先不使用 .pyd 文件。 新建一个fast_tanh.pyx 文件，文件内容如下。 12345678# distutils: language = c++# cython: language_level = 3cdef extern from &quot;mytanh.cpp&quot;: double mytanh(double x) def fast_tanh(double x): return mytanh(x) 下面我们来解释每条语句的作用。其中 12# distutils: language = c++# cython: language_level = 3 这两行注释是用于配置编译器的特殊注释，分说明了使用的是 C++ 和 Python3。 12cdef extern from &quot;mytanh.cpp&quot;: double mytanh(double x) Cython 使用 cdef extern from 来声明一个在 C++ 中实现的函数。上述代码声明了 mytanh 函数，使其可以在 Cython 中使用。虽然 mytanh 现在可以在 Cython 中直接调用了，但 Python 并不能直接调用该函数，因此还要声明一个接口函数，命名为 fast_tahn。 123# 此函数完成了“包装”的工作，即完成了从 Python 类型到 C++ 类型的转换def fast_tanh(double x): # def fast_tanh(x) 也是可行的 return mytanh(x) 上述代码声明了一个接口函数，前面所述的“包装”工作就是这个函数完成的，完成包装后，Python 能直接调用的是这个 fast_tanh 函数，而不是原始的 mytanh 函数。Cython 的语法与 Python 非常相似，若去掉形参中的 double 也是可行的，但若 Cython 知道参数的类型可以加速运行速度。Cython 支持大部分普通的 Python 代码，因此可以在 Cython 中将 Python 的数据类型和 C++ 的数据类型相互转换，例如可以将 vector 转为 numpy array。若要使用 vector 类型，还需在开头加上 from libcpp.vector cimport vector。 编写 setup.pyfast_tanh.pyx 编写完后，需要编译后才能被 Python 调用，编译是通过 setup.py 进行的。 12345678910111213from distutils.core import setup, Extensionfrom Cython.Build import cythonizesetup(ext_modules=cythonize(Extension( 'fast_tanh', # 生成的模块名称 sources=['fast_tanh.pyx'], # 要编译的文件 language='c++', # 使用的语言 include_dirs=[], # gcc的-I参数 library_dirs=[], # gcc的-L参数 libraries=[], # gcc的-l参数 extra_compile_args=[], # 附加编译参数 extra_link_args=[], # 附加链接参数))) 其他参数可以根据需要添加，如果你暂时还不知道这些参数有什么用，那么可以先空着。将上述代码保存到 setup.py 后，运行如下命令即可编译 Cython 文件。 1python setup.py build_ext --inplace 需要注意，编译时的 Python 版本必须和调用时使用的 Python 版本相同。编译完成后，当前目录下会自动生成相应的 cpp 文件和 pyd 文件，在 Linux 上是 so 文件。 如果使用了 numpy 会在编译过程中看到警告： 1Warning Msg: Using deprecated NumPy API, disable it with #define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION 该警告可以忽略，因为 Cython 使用的是已经弃用的 Numpy API，不影响使用。 在 Python 中调用 fast_tanh 函数完成了编译的步骤后，fast_tanh在 Python 中就和一个普通的 Python 模块一样，可以使用 import 来导入 1from fast_tanh import fast_tanh # 从 fast_tanh.pyx 中导入 fast_tanh 函数 导入后，就可以在 Python 中像调用普通函数一样，直接使用 fast_tanh 函数了，完整代码如下，与之前的区别仅仅是把 tanh 替换成了 fast_tanh，非常方便。 12345678910from random import randomfrom time import timefrom fast_tanh import fast_tanhdata = [random() for i in range(1000000)] # 生成随机数据start_time = time() # 计算并统计时间result = list(map(fast_tanh, data))end_time = time()print(end_time - start_time) # 输出运行时间 测试运行速度，运行上述代码共需 0.18 秒，可以看到，仅仅替换了一个 tanh 函数后性能提升了近 8 倍。如果有其他更复杂的操作，可以提升几十倍甚至上百倍的性能。 Python 调用 C/C++ 类前面我们调用了 C/C++ 的函数，但如果我们有更多内容需要用 C/C++ 重写，想调用 C++ 编写的类呢？其实方法大同小异，主要的步骤还是在 Cython 中声明后，进行“包装”，编译，最后就可以在 Python 中调用了。 编写一个 C++ 类我们以一个简单的矩形类为例，假设我们在 C++ 中编写了一个矩形类。头文件 Rectangle.h 为： 123456789101112131415161718#ifndef RECTANGLE_H#define RECTANGLE_Hnamespace shapes &#123; class Rectangle &#123; public: int x0, y0, x1, y1; // 矩形对角线上的两个点坐标 Rectangle(); Rectangle(int x0, int y0, int x1, int y1); ~Rectangle(); int getArea(); void getSize(int* width, int* height); void move(int dx, int dy); &#125;;&#125;#endif Rectangle.cpp 中的实现为： 123456789101112131415161718192021222324252627282930#include &lt;iostream&gt;#include \"Rectangle.h\"namespace shapes &#123; // 构造函数 Rectangle::Rectangle () &#123;&#125; Rectangle::Rectangle (int x0, int y0, int x1, int y1) &#123; this-&gt;x0 = x0; this-&gt;y0 = y0; this-&gt;x1 = x1; this-&gt;y1 = y1; &#125; // 析构函数 Rectangle::~Rectangle () &#123;&#125; // 获取矩形面积 int Rectangle::getArea () &#123; return (this-&gt;x1 - this-&gt;x0) * (this-&gt;y1 - this-&gt;y0); &#125; // 获取矩形的边长 void Rectangle::getSize (int *width, int *height) &#123; (*width) = x1 - x0; (*height) = y1 - y0; &#125; // 移动矩形 void Rectangle::move (int dx, int dy) &#123; this-&gt;x0 += dx; this-&gt;y0 += dy; this-&gt;x1 += dx; this-&gt;y1 += dy; &#125;&#125; 在 Cython 中声明类接下来需要在 Cython 中编写一个接口。与前面调用 C++ 函数类似，使用 cdef extern from 来声明一个在 C++ 中实现的类： 1cdef extern from \"Rectangle.h\" namespace \"shapes\": 若没有命名空间，则使用： 1cdef extern from \"Rectangle.h\" 我们现在使用 .pxd 文件，其实如果一定要像刚才一样放在一个文件里也是可以的。将声明放在 Rectangle.pxd 文件中，.pxd 文件相当于 C++ 的 .h 文件，专门用于声明： 1234567891011cdef extern from &quot;Rectangle.cpp&quot;: pass# 用cdef声明类cdef extern from &quot;Rectangle.h&quot; namespace &quot;shapes&quot;: cdef cppclass Rectangle: Rectangle() except + Rectangle(int, int, int, int) except + int x0, y0, x1, y1 int getArea() void getSize(int* width, int* height) void move(int, int) 由于 .h 文件中没有实现矩形类，还要使用下面的语句来包含 Rectangle.cpp 中实现的代码 12cdef extern from &quot;Rectangle.cpp&quot;: pass cdef cppclass Rectangle 声明了一个在 C++ 中定义的类，其他函数的声明与前面调用函数类似。在构造函数后加上 except + 可以使 Python 能够捕获到在构造函数中发生的异常，若不加 except +，则 Cython 不会处理构造函数中发生的异常。 在 Cython 中编写接口类与前面相同，虽然现在 C++ 中的类在 Cython 中可以直接访问了，但在 Python 中并不能访问。因此，我们还需要实现一个接口类，用于在 Python 中调用。注意，C++ 类的声明放在 .pxd 文件中, 接口类的实现放在 .pyx 中。PyRectangle.pyx为 : 1234567891011121314151617# distutils: language = c++from Rectangle cimport Rectangle# 接口类# Python可以直接访问接口类，接口类可以直接访问C++类cdef class PyRectangle: cdef Rectangle c_rect # 存储C++对象 def __cinit__(self, int x0, int y0, int x1, int y1): self.c_rect = Rectangle(x0, y0, x1, y1) def get_area(self): return self.c_rect.getArea() def get_size(self): cdef int width, height self.c_rect.getSize(&amp;width, &amp;height) return width, height def move(self, dx, dy): self.c_rect.move(dx, dy) 现在，PyRectangle 类就像普通的 Python 类一样可以直接在 Python 中调用了。 另外，Cython 也支持使用 new 创建 C++ 对象 12def __cinit__(self, int x0, int y0, int x1, int y1): self.c_rect = new Rectangle(x0, y0, x1, y1) 与 C++ 相同，使用了 new 就必须使用 delete 释放内存，否则会造成内存泄漏。 12def __dealloc__(self): # 析构函数 del self.c_rect # 释放内存 编译setup.py 内容如下 12345678910111213from distutils.core import setup, Extensionfrom Cython.Build import cythonizesetup(ext_modules=cythonize(Extension( 'PyRectangle', # 生成的模块名称 sources=['PyRectangle.pyx'], # 要编译的文件 language='c++', # 使用的语言 include_dirs=[], # gcc的-I参数 library_dirs=[], # gcc的-L参数 libraries=[], # gcc的-l参数 extra_compile_args=[], # 附加编译参数 extra_link_args=[], # 附加链接参数))) 使用 python setup.py build_ext --inplace 编译 在 Python 中调用接口类现在，PyRectangle 类就和普通的 Python 类一样，可以直接被 Python 调用 12345import PyRectanglex0, y0, x1, y1 = 1, 2, 3, 4rect = PyRectangle.PyRectangle(x0, y0, x1, y1)print(rect.get_area) 运行该程序，输出了矩形面积，调用成功。 总结通过 Cython 调用 C/C++ 的原理是： Python -&gt; Cython 接口 -&gt; C/C++ 访问 C++ 都是通过 Cython 接口完成的。 若还想了解更多，可以阅读 Cython 文档 参考资料 https://www.bookstack.cn/read/cython-doc-zh/README.md https://www.youtube.com/watch?v=D9RlT06a1EI&amp;t=45s","categories":[{"name":"Python","slug":"Python","permalink":"https://iqhy.github.io/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://iqhy.github.io/tags/Python/"},{"name":"C++","slug":"C","permalink":"https://iqhy.github.io/tags/C/"}]},{"title":"蒙特卡洛树搜索 MCTS 入门","slug":"蒙特卡洛树搜索 MCTS 入门","date":"2019-10-28T07:46:02.000Z","updated":"2021-03-26T07:26:26.606Z","comments":true,"path":"posts/2019/1028154602/","link":"","permalink":"https://iqhy.github.io/posts/2019/1028154602/","excerpt":"【内容简介】蒙特卡洛树搜索(Monte Carlo Tree Search) ，是一种寻找最优决策的方法。","text":"【内容简介】蒙特卡洛树搜索(Monte Carlo Tree Search) ，是一种寻找最优决策的方法。 蒙特卡洛树搜索(Monte Carlo Tree Search) 是一种寻找最优决策的方法，在AlphaGo中被运用，其主要分为四步：选择(Selection)，拓展(Expansion)，模拟(Simulation)，反向传播(Backpropagation)。 本文以井字棋为例对这一方法进行介绍。 基础知识介绍 MCTS 的具体搜索算法之前，先介绍一下 MCTS 的基础知识。 节点在棋类问题中，MCTS 使用一个节点来表示一个游戏状态，换句话说，每一个节点都对应着井字棋中的一种情况。假设现在井字棋的棋盘上只有中间一个棋子，图中用 ○ 画出，我们用一个节点表示这个游戏状态，这个节点就是下图中的根节点。这时，下一步棋有 8 种下法，所以对应的，这个根节点就有 8 个子节点（受图片大小限制，图中只画出了 3 个）。 下完一步后，游戏还没有结束，棋盘上还可以继续下棋，继续按照刚才的方法，一个节点表示一个游戏状态，这些子节点又有子节点，所有的井字棋游戏状态都可以被这样表示，于是它们就构成了一个树。对于围棋或者其他更复杂的棋类也是一样，只不过这个树会更大、更复杂。蒙特卡洛树搜索就是要在这样一个树中搜索出下一步在哪个位置下棋最有可能获胜，即根节点的哪个子节点获胜概率最高。 节点的两个属性在蒙特卡洛树搜索中，我们将节点记作 $v$，在搜索过程中需要记录节点的访问次数和累计奖励，它们的表示符号如下： $N(v)$：节点 $v$ 的访问次数，节点在搜索过程中被访问多少次，该值就是多少。 $Q(v)$：节点 $v$ 的累计奖励，即节点在反向传播过程中获得的所有奖励(reward)求和。 所谓的奖励(reward)是一个数值，游戏结束时若获胜，奖励为 1，若失败，奖励为 0。 搜索过程下面介绍 MCTS 的具体搜索算法。 给定当前游戏状态，如何获得下一步的最佳下法呢？对于井字棋来说，当然可以在整个决策树中遍历所有可能性，直接找出最优策略。但若换成围棋等复杂的棋类，遍历的方法是显然不可行的，这时就需要在决策树中有选择地访问节点，并根据现有的有限信息做出最优决策。 在介绍下面的搜索过程之前，我们首先要知道：蒙特卡洛树搜索搜的是什么？换句话说，假如我们先把 MCTS 看成一个黑盒子，那么它的输入和输出分别是什么？ 输入：一个游戏状态 输出：下一步下棋的位置 也就是说，给 MCTS 一个棋局，它就告诉你下一步该怎么走。知道了输入输出分别是什么后，我们再来看看从输入到输出这中间，MCTS 到底做了什么。总的来说，MCTS 按顺序重复执行以下四个步骤：选择，拓展，模拟，反向传播。 选择(Selection)根据上文所述，对于围棋等可能性非常多的问题，遍历的方法不可行，因此 MCTS 有选择地访问节点，这就是选择阶段。从根节点(就是输入)出发，根据一定的策略，向下选择一个节点进行访问，若被选择的节点未被访问过，则执行扩展；若被选择的节点已被访问，则访问该节点，并继续向下选择节点进行访问，直到遇见未被访问的节点，或遇见终止节点(游戏结束)。 选择的策略由该公式确定，对当前节点的每个子节点计算如下公式，并选择计算结果最大的节点。$$\\underset{v’\\in \\text{children of }v}{\\mathrm{argmax}}\\frac{Q\\left( v’ \\right)}{N\\left( v’ \\right)}+c\\sqrt{\\frac{\\text{2}\\ln N\\left( v \\right)}{N\\left( v’ \\right)}}$$其中， $v$ 表示父节点，$v’$ 表示子节点。$c$ 是一个常数，用于权衡探索 (Exploration) 与利用 (Exploitation)。探索是指选择一些之前没有尝试过的下法，丰富自己的知识，新的知识可能带来不错的结果；而利用是指根据现有的知识选择下法。$c$ 越大，就越偏向于探索；$c$ 越小，就越偏向于利用。 扩展 (Expansion)MCTS 在搜索的过程中是有选择地访问节点，并把所有访问过的节点构建成一个树。扩展就是把选择步骤中遇到的未访问节点添加到树中，然后对该节点执行模拟。 模拟 (Simulation)模拟是一个粗略获取信息的过程。从被扩展的节点开始，对游戏进行模拟，也就是在棋盘上随机下棋，直到游戏结束。若此时游戏胜利，则奖励 (Reward) 记为 $1$；若游戏失败，奖励记为 $0$。 注：在其他应用中，奖励也可是其他值。 反向传播 (Backpropagation)反向传播是将在模拟中得到的奖励更新的过程。为什么叫反向传播呢？回顾一下第一步选择，我们从根节点向下一步一步地选择节点进行访问，现在我们将沿着这条路逐一更新节点信息，重新回到根节点，所以叫反向传播。 将获得的奖励记作 $R$，对当前节点，及其路径上的所有节点 $v$，都执行以下操作。即，更新访问次数，对奖励进行累加。$$N(v)=N(v)+1 \\\\Q(v)=Q(v)+R$$我们再回头看看选择步骤中的公式$$\\underset{v’\\in \\text{children of }v}{\\mathrm{argmax}}\\frac{Q\\left( v’ \\right)}{N\\left( v’ \\right)}+c\\sqrt{\\frac{\\text{2}\\ln N\\left( v \\right)}{N\\left( v’ \\right)}}$$可以看到，式中第一项其实就是该节点在前面的过程中获得的平均奖励，自然第一项的值越大，在现有的知识下，选择该节点更有可能获胜。式中第二项，当该节点访问次数占父节点次数的比例越小时，该值越大，表示该节点访问次数很少，可以多进行尝试，获取新的知识，它们也可能获得更丰厚的回报。于是 $c$ 就是控制这两者重要程度的参数。 这就是上限置信区间算法 (Upper Confidence Bound )。 搜索过程展示下面我们看一张动图以帮助理解，图中节点内数字表示 $Q(v)/N(v)$，加粗的线条表示正在访问的路径，折线表示模拟。 搜索结束MCTS 的整个过程就是这样，那么什么时候结束呢？一般设置以下两个终止条件。 设置最大根节点搜索次数，达到该次数后结束搜索。 设置最大搜索时间，超过时间后结束搜索。 结束后，就输出当前状态下，下一步下棋的位置。 选择最佳节点搜索结束后，如何选择下一步下棋的位置呢？ 不是选择 $Q$ 最大的节点，也不是选择平均奖励最大的节点，而是选择访问次数最多的节点。这样，就得到了当前游戏状态(根节点)下的一个选择。或者，也可以将访问次数归一化，作为下一步的概率。 如果下一步还要进行决策，则又要将下一步的状态作为根节点，重新执行 MCTS，并选择访问次数最多的节点作为下一步的策略。(上一步的搜索结果可以保留) 以上只是 MCTS 的简单介绍，想更详细的了解 MCTS 可以参考论文 A Survey of Monte Carlo Tree Search Methods 另外，Github 上也已经有 MCTS 的 Python 实现源码 https://github.com/pbsinclair42/MCTS。文档比较全，有详细的例子。","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://iqhy.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"mcts","slug":"mcts","permalink":"https://iqhy.github.io/tags/mcts/"}]}]}