{"meta":{"title":"iqhy's Blog","subtitle":null,"description":null,"author":"iqhy","url":"https://iqhy.github.io","root":"/"},"pages":[{"title":"","date":"2019-10-28T08:11:52.236Z","updated":"2019-10-28T08:11:52.236Z","comments":true,"path":"404.html","permalink":"https://iqhy.github.io/404.html","excerpt":"","text":"404 Page 404 找不到页面 返回上一页 返回首页"},{"title":"","date":"2019-10-28T08:09:04.522Z","updated":"2019-02-14T22:23:50.000Z","comments":true,"path":"404_css/style.css","permalink":"https://iqhy.github.io/404_css/style.css","excerpt":"","text":"body { background-color: #2F3242; } svg { position: absolute; top: 50%; left: 50%; margin-top: -250px; margin-left: -400px; } .message-box { height: 200px; width: 380px; position: absolute; top: 50%; left: 50%; margin-top: -100px; margin-left: 50px; color: #FFF; font-family: Roboto; font-weight: 300; } .message-box h1 { font-size: 60px; line-height: 46px; margin-bottom: 40px; } .buttons-con .action-link-wrap { margin-top: 40px; } .buttons-con .action-link-wrap a { background: #68c950; padding: 8px 25px; border-radius: 4px; color: #FFF; font-weight: bold; font-size: 14px; transition: all 0.3s linear; cursor: pointer; text-decoration: none; margin-right: 10px } .buttons-con .action-link-wrap a:hover { background: #5A5C6C; color: #fff; } #Polygon-1 , #Polygon-2 , #Polygon-3 , #Polygon-4 , #Polygon-4, #Polygon-5 { -webkit-animation: float 1s infinite ease-in-out alternate; animation: float 1s infinite ease-in-out alternate; } #Polygon-2 { -webkit-animation-delay: .2s; animation-delay: .2s; } #Polygon-3 { -webkit-animation-delay: .4s; animation-delay: .4s; } #Polygon-4 { -webkit-animation-delay: .6s; animation-delay: .6s; } #Polygon-5 { -webkit-animation-delay: .8s; animation-delay: .8s; } @-webkit-keyframes float { 100% { -webkit-transform: translateY(20px); transform: translateY(20px); } } @keyframes float { 100% { -webkit-transform: translateY(20px); transform: translateY(20px); } } @media (max-width: 450px) { svg { position: absolute; top: 50%; left: 50%; margin-top: -250px; margin-left: -190px; } .message-box { top: 50%; left: 50%; margin-top: -100px; margin-left: -190px; text-align: center; } }"},{"title":"关于","date":"2020-02-28T03:11:20.000Z","updated":"2020-02-29T08:57:52.328Z","comments":false,"path":"about/index.html","permalink":"https://iqhy.github.io/about/index.html","excerpt":"","text":"作者：Yu Hanqing github: https://github.com/iqhy email: imyuhanqing@outlook.com"},{"title":"文章分类","date":"2019-10-28T07:29:43.000Z","updated":"2020-02-28T06:04:21.234Z","comments":false,"path":"categories/index.html","permalink":"https://iqhy.github.io/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2019-10-24T15:22:28.000Z","updated":"2020-02-28T06:05:20.339Z","comments":false,"path":"tags/index.html","permalink":"https://iqhy.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"MDP 基本概念 (一)","slug":"MDP 基本概念 (一)","date":"2020-06-19T15:24:37.000Z","updated":"2020-06-19T16:11:55.753Z","comments":true,"path":"posts/2020/0619232437/","link":"","permalink":"https://iqhy.github.io/posts/2020/0619232437/","excerpt":"本文将简要介绍马尔可夫过程 (Markov Processes) 与马尔可夫奖励过程 (Markov Reward Processes)。","text":"本文将简要介绍马尔可夫过程 (Markov Processes) 与马尔可夫奖励过程 (Markov Reward Processes)。 前言最近准备写一个系列，从 MDP 到部分可观测 MDP (POMDP), 再到分布式 MDP(Dec-POMDP)。 要了解马尔可夫决策过程 (Markov Decision Processes)，首先要了解马尔可夫过程 (Markov Processes)和马尔可夫奖励过程 (Markov Reward Processes)，这两者是 MDP 的基础。本文将按如下顺序介绍 马尔可夫过程 (Markov Processes) 马尔可夫奖励过程 (Markov Reward Processes) 马尔可夫决策过程 (Markov Decision Processes) 马尔可夫过程 (Markov Processes)马尔可夫性质 (Markov Property)马尔可夫过程为什么叫这个名字呢，因为它具有马尔可夫性质。马尔可夫性质简而言之，就是未来发生的事情只与当前状态有关而与过去无关，是一个无记忆的过程，它要求状态包含可能对未来产生影响的所有信息。 下面举一个例子，假设每天的天气有三种状态：晴天、阴天、下雨。我们将第 $i$ 天的状态记为 $s_i$ ，如果第 7 天下雨，那么$$s_7=下雨$$第 7 天下雨仅仅取决于第 6 天的状态，若第 6 天天晴，则第七天有0.2的概率下雨；若第 6 天阴天，则第七天有0.3 的概率下雨；若第 6 天阴天，则第七天有 0.5 的概率下雨；第 7 天下雨的概率只与第 6 天有关，而与前面 5 天的状态无关，这就是马尔可夫性质，用数学公式来描述就是$$\\mathbb{P}\\left[ S_{t+1}|S_t \\right] =\\mathbb{P}\\left[ S_{t+1}|S_t,S_{t-1},…,S_1 \\right]$$ 状态转移矩阵 (State Transition Matrix)很容易可以看出来，由于只有三种天气，前后两天的天气组合共有 $3\\times 3=9$ 种。将这9个概率按一定规则写进矩阵，就是状态转移矩阵。 那这个规则是怎样的呢？若我们将天晴、阴天、下雨这三种状态编号为 1、2、3，则状态转移矩阵中的第 $i$ 行，第 $j$ 列的元素意义如下$$P_{ij}=\\mathbb{P}\\left[ S_{t+1}=\\text{状态}i|S_t=\\text{状态}j \\right]$$换句话说，就是前一天天气为状态 $i$，后一天天气为状态 $j$ 的概率，按照这样的规则，整个状态转移矩阵 $P$ 为$$\\begin{matrix} &amp; \\text{to}\\newline P=\\text{from}&amp; \\left[ \\begin{matrix} P_{11}&amp; P_{12}&amp; P_{13}\\newline P_{21}&amp; P_{22}&amp; P_{23}\\newline P_{31}&amp; P_{32}&amp; P_{33}\\newline\\end{matrix} \\right]\\\\end{matrix}$$ 不难看出，状态转移矩阵 $P$ 每一行的和都为 1，因为概率之和必为 1。 马尔可夫过程的定义马尔可夫过程就是具有马尔可夫性的随机过程，上述天气的例子描述了一个满足马尔可夫性、随着时间的推移，天气不断随机变化的过程，这就是一个马尔可夫过程。一个马尔可夫过程可由 $&lt;S,P&gt;$ 两个参数完全确定，这两个参数确定了，整个模型就确定了。其中 $S$ 是所有状态的集合，在刚才的例子中 $S$ 就是三种不同的天气组成的集合 $P$ 是状态转移矩阵 例子将前面描述天气变化的马尔可夫过程画成图，如下图所示。马尔可夫过程都可以用这样的图来表示。 下面我们看一个稍微复杂一点的例子，这是一个描述学生学习的马尔可夫过程，在这个例子中，学生共有三节课要学习，在上课过程中，学生有一定概率走神，去刷 Facebook或睡觉，也有可能去酒吧，还有可能坚持把三堂课学完，最终通过考试，按照同样的方法画成图，如下图所示。 将其状态转移概率写成状态转移矩阵，如该公式所示，可以看到，该矩阵的每行之和都是1。$$P=\\begin{matrix} &amp; \\begin{matrix} \\text{C}1&amp; \\text{C}2&amp; \\text{C}3&amp; \\text{Pass}&amp; \\text{Pub}&amp; \\text{FB}&amp; \\text{Sleep}\\newline\\end{matrix}\\newline \\begin{array}{l} \\text{C}1\\newline \\text{C}2\\newline \\text{C}3\\newline \\text{Pass}\\newline \\text{Pub}\\newline \\text{FB}\\newline \\text{Sleep}\\newline\\end{array}&amp; \\left[ \\begin{matrix} \\ \\ \\quad &amp; 0.5&amp; \\ \\ \\quad &amp; \\ \\ \\quad &amp; \\ \\ \\quad &amp; 0.5&amp; \\ \\ \\quad \\newline \\ \\ &amp; \\ \\ &amp; 0.8&amp; \\ \\ &amp; \\ \\ &amp; \\ \\ \\qquad&amp; 0.2\\newline \\ \\ &amp; \\ \\ &amp; \\ \\ &amp; 0.6&amp; 0.4&amp; \\ \\ &amp; \\ \\ \\newline \\ \\ &amp; \\ \\ &amp; \\ \\ &amp; \\ \\ &amp; \\ \\ &amp; \\ \\ &amp; 1.0\\newline 0.2&amp; 0.4&amp; 0.4&amp; \\ \\ &amp; \\ \\ &amp; \\ \\ &amp; \\ \\ \\newline 0.1&amp; \\ \\ &amp; \\ \\ &amp; \\ \\ &amp; \\ \\ &amp; 0.9&amp; \\ \\ \\newline \\ \\ &amp; \\ \\ &amp; \\ \\ &amp; \\ \\ &amp; \\ \\ &amp; \\ \\ &amp; 1.0\\newline\\end{matrix} \\right]\\\\end{matrix}$$与刚才天气的例子不同，这个马尔可夫过程有一个终止状态，一旦进入这个状态，整个过程就结束了，这个状态通常可能是游戏结束的状态。为了与其他普通状态一起表示，这个终止状态可以视为以概率 1 转移到自身，这样做的目的是方便处理。 马尔可夫奖励过程马尔可夫过程加上奖励就是马尔可夫奖励过程，为什么需要有奖励呢？ 我们对环境进行 MDP 建模的目的是为了让机器能够在环境中学习出好的策略，机器怎么学习呢，光有转移概率是不够的，靠的是奖励。奖励可正也可负，若当前状态对我们有利，就给正奖励；若当前状态对我们不利，就给负奖励。 定义马尔可夫奖励过程是带奖励的马尔可夫过程，一个马尔可夫过程可由 $&lt;S,P,R,\\gamma&gt;$ 四个参数完全确定。 $S$ 是所有状态的集合，在刚才的例子中 $S$ 就是三种不同的天气组成的集合 $P$ 是状态转移矩阵 $R$ 是奖励，每个状态都对应有一个奖励 $\\gamma$ 是折损因子 (discount factor)，$\\gamma \\in[0,1]$，这个后面解释，是用来选择“短视”或“远视”的。 例子上述学生学习的马尔可夫过程加上奖励后，如下图所示 学习的目的是为了通过考试，所以是正奖励；而学习的过程中比较枯燥、辛苦，给负奖励；临时去酒吧能暂时感到快乐，给较小的正奖励。我们最终的目标是为了取得尽可能高的奖励。 若某学生的学习过程是 C1 C2 C3 Pass Sleep，那么在整个过程中获得的奖励是4；若某学生的学习过程是 C1 FB FB C1 C2 Sleep，那么在整个过程中获得的奖励是 -8。 回报回报 (return) $G_t$ 定义为从时刻 $t$ 开始，之后获取的所有折损奖励求和$$G_t=R_{t+1}+\\gamma R_{t+2}+…=\\sum_{k=0}^{\\infty}{\\gamma ^kR_{t+k+1}}$$由于 $\\gamma \\in[0,1]$，$\\gamma$ 控制着对未来奖励的关心程度。若 $\\gamma=0$，$G_t$ 退化为 $G_t=R_{t+1}$ 意味着最短视，不关心未来的奖励，只关心当前的奖励；若 $\\gamma=1$，意味着最远视，未来的奖励非常重要。 $\\gamma$ 越接近 $0$ 则越短视 $\\gamma$ 越接近 $1$ 则越远视 要注意的是回报与前面在整个过程中获得的奖励获得的奖励是不同的，回报是站在当前的视角下考虑未来，而前面是实际已经结束了，再回头统计。 为什么需要折损因子大多数 MRP 或 MDP 中都引入了折损因子，这是为什么呢？主要有以下几个方面的原因。 数学处理方便 防止回报 $G_t$ 趋于正无穷 模型与现实存在偏差，越远的未来可能偏差越大 在金融等领域有实际物理意义 与人类和动物的行为类似，人们更喜欢及时奖励 总结马尔可夫过程就是满足马尔可夫性质的随机过程，为了让机器在环境中学习，引入了奖励。奖励分为即时奖励和未来奖励，折损因子 $\\gamma$ 用于平衡“短视”与“远视”。","categories":[{"name":"MDP","slug":"MDP","permalink":"https://iqhy.github.io/categories/MDP/"}],"tags":[{"name":"MDP","slug":"MDP","permalink":"https://iqhy.github.io/tags/MDP/"},{"name":"机器学习","slug":"机器学习","permalink":"https://iqhy.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"使用 Python 和 C++ 并行 MCTS","slug":"使用 Python 和 C++ 并行 MCTS","date":"2020-03-15T13:03:55.000Z","updated":"2020-03-15T15:47:02.573Z","comments":true,"path":"posts/2020/315210355/","link":"","permalink":"https://iqhy.github.io/posts/2020/315210355/","excerpt":"简单介绍在 Python 和 C++ 中蒙特卡洛树搜索 (MCTS) 的并行化方法。","text":"简单介绍在 Python 和 C++ 中蒙特卡洛树搜索 (MCTS) 的并行化方法。 前言当我们在 Python 中实现了 MCTS 后，可能会遇到性能问题，这时就需要将 MCTS 并行化。MCTS 的并行方法主要分为三种： 叶并行 (leaf parallelization), 即在叶节点扩展时进行并行。 根并行 (root parallelization), 即直接使用进程或线程创建多个不同的树，在不同的树中同时执行搜索。 树并行 (tree parallelization), 即多个线程在同一个树中进行并行，每个线程在树的不同部分执行搜索。 这些并行方法的详细介绍可以参考这篇论文的第 25 页。 图1 MCTS的并行化方法[1] 叶并行叶并行的方法比较简单，只需在遇到叶节点时，同时执行多次模拟 (simulation)，然后使用多次模拟的结果来代替之前的结果即可。但是在 AlphaZero 的算法中，叶并行的方法并不适用。因为该算法实际上并没有模拟 (simulation) 这个过程，而是使用神经网络直接返回当前节点的评估结果，因此需要使用其他并行方法。AlphaZero 的原理可以参考这篇文章。 根并行根并行的实现同样比较简单，只要使用 Multiprocessing 或 concurrent.futures.ProcessPoolExecutor 直接调用 MCTS 即可。 1234567891011121314import multiprocessing as mpdef mcts_main(a, b): ''' mcts搜索的主函数 输入参数：a, b ''' ...p = mp.Pool(10) # 10个进程 for i in range(50): # 50个待执行任务 p.apply_async(mcts_main, args=(a, b))p.close()p.join() 如果在 MCTS 中调用了 GPU 版的 Keras，需要设置显存按需增长，并且要将 import keras 放在函数内，否则将不能并行调用 model.predict() 123456789import tensorflow as tfconfig = tf.ConfigProto()config.gpu_options.allow_growth = Truesession = tf.Session(config=config)def mcts_main(a, b): import keras # import keras要放在函数内 # mcts搜索的主函数 ... 这样并行虽然简单，但缺点是程序占内存大，且显存容易不够用。 树并行在 Python 中直接按照上述方法并行后，可能还是无法满足需求，需要更高效的并行方法。由于 GIL 的限制，在Python 中不能使用多线程来并行 MCTS，但实现树并行时需要进程/线程间较多的通信，如果直接在 Python 中用 multiprocessing 实现，可能带来较大的性能损失，同时实现起来也比较困难[2]。 一种解决方法是用 C++ 实现树并行，再封装成 Python 接口，在 Python 中调用，这样就避开了 GIL 的限制。C++ 的树并行实现可以参考这个 Github 项目 。这个项目使用的是 PyTorch，如果你使用的是 Keras，要在 C++ 中调用 Keras 可以参考这篇文章。将 C++ 封装成 Python 接口可以参考这篇文章。 封装成 Python 接口后，由于避开了 GIL 的限制，可以直接通过多线程调用。 123456789101112131415import concurrent.futuresdef mcts_main(a, b): ''' mcts搜索的主函数 输入参数：a, b ''' ...# 最大线程数10，50个待执行任务with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor: futures = [executor.submit(mcts_main, a, b) for i in range(50)] for future in concurrent.futures.as_completed(futures): result = future.result() ... 参考资料[1] Browne, C. B., Powley, E., Whitehouse, D., Lucas, S. M., Cowling, P. I., Rohlfshagen, P., … &amp; Colton, S. (2012). A survey of monte carlo tree search methods. IEEE Transactions on Computational Intelligence and AI in games, 4(1), 1-43. [2] https://stackoverflow.com/questions/52584142/mcts-tree-parallelization-in-python-possible 本人水平有限，如有不足之处，欢迎指出。","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://iqhy.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://iqhy.github.io/tags/Python/"},{"name":"C++","slug":"C","permalink":"https://iqhy.github.io/tags/C/"},{"name":"mcts","slug":"mcts","permalink":"https://iqhy.github.io/tags/mcts/"},{"name":"Keras","slug":"Keras","permalink":"https://iqhy.github.io/tags/Keras/"}]},{"title":"在 C++ 中调用 keras","slug":"在 C++ 中调用 keras","date":"2020-02-29T08:18:32.000Z","updated":"2020-06-13T02:01:18.432Z","comments":true,"path":"posts/2020/0229161832/","link":"","permalink":"https://iqhy.github.io/posts/2020/0229161832/","excerpt":"使用 frugally-deep 在 C++ 中轻松调用 Keras 模型","text":"使用 frugally-deep 在 C++ 中轻松调用 Keras 模型 Keras 使用起来非常方便，我们有时候需要在 C++ 中调用训练好的模型，希望在 C++ 中调用 Keras 的 model.predict()，但 Keras 并没有提供 C++ API。一种解决方法是使用 TensorFlow 的 C++ API，但编译过程非常繁琐，容易失败。这里我们使用另一种方法，使用 Github 上的 frugally-deep。 介绍frugally-deep 是一个用 C++ 实现的库，它可以将 Keras 保存的 .h5 文件直接转为 C++ 中可调用的 .json 文件，经过一步转换后就可以直接调用。frugally-deep 使用起来比较简单，支持非常多常用的模型，无需编译 TensorFlow。同时它也是线程安全的，可以很方便的在多 CPU 上进行前向传播。另外，frugally-deep 不支持使用 GPU，如果不是必须要使用 GPU，frugally-deep 是一个很好的选择。 支持的模型frugally-deep 支持大多数常用的模型 Add, Concatenate, Subtract, Multiply, Average, Maximum AveragePooling1D/2D, GlobalAveragePooling1D/2D Bidirectional, TimeDistributed, GRU, LSTM, CuDNNGRU, CuDNNLSTM Conv1D/2D, SeparableConv2D, DepthwiseConv2D Cropping1D/2D, ZeroPadding1D/2D BatchNormalization, Dense, Flatten Dropout, AlphaDropout, GaussianDropout, GaussianNoise SpatialDropout1D, SpatialDropout2D, SpatialDropout3D MaxPooling1D/2D, GlobalMaxPooling1D/2D ELU, LeakyReLU, ReLU, SeLU, PReLU Sigmoid, Softmax, Softplus, Tanh UpSampling1D/2D Reshape, Permute Embedding 以及 multiple inputs and outputs nested models residual connections shared layers variable input shapes arbitrary complex model architectures / computational graphs custom layers (by passing custom factory functions to load_model) 安装frugally-deep 的安装很简单，可以使用官方安装教程 INSTALL.md 上的命令安装，也可以直接下载源码。使用命令安装的方法在官方的教程中已经很详细了，所以这里采用直接下载源码的方式。 使用 frugally-deep 前需要有 (截止2020年6月13日) 一个支持 C++14 的编译器 Python 版本在 3.7 或以上 TensorFlow 2.1.1 如果你正在使用 Tensorflow 1.x 的 Keras，安装 TensorFlow 2.x.x 后大多数情况下只需要把 import keras 修改为 import tensorflow.keras 即可，Keras 的改动并不大。 下载源码分别前往frugally-deep, FunctionalPlus , Eigen 和 json 点击右侧的 Clone or download 再点击 Download ZIP 下载这些源码。 解压假设现在代码根目录下的源文件只有 main.cpp，文件结构为： 1+-- main.cpp 将 frugally-deep 源码中的 include 文件夹和 keras_export 文件夹解压到与 main.cpp 相同的目录下： 1234+-- include| +-- fdeep+-- keras_export+-- main.cpp 将 FunctionalPlus 源码中 include 文件夹内的 fplus 文件夹复制到 main.cpp 相同目录下的 include 文件夹内： 12345+-- include| +-- fdeep| +-- fplus+-- keras_export+-- main.cpp 同样，将 json 源码中 include 文件夹内的 nlohmann 文件夹复制到 main.cpp 相同目录下的 include 文件夹内： 123456+-- include| +-- fdeep| +-- fplus| +-- nolhmann+-- keras_export+-- main.cpp 最后将 eigen 源码中 Eigen 文件夹放在 main.cpp 相同目录下的 include 文件夹内 1234567+-- include| +-- Eigen| +-- fdeep| +-- fplus| +-- nolhmann+-- keras_export+-- main.cpp 需要的文件已经安装完成，下面可以开始使用了。 使用总的来说，使用 frugally-deep 的步骤为： 在 Python 中训练好模型后，使用 model.save(&#39;....h5&#39;, include_optimizer=False) 保存模型 使用 keras_export/convert_model.py 将 .h5 模型转换成 C++ 模型 在 C++ 中使用 fdeep::load_model(...) 加载模型 在 C++ 中使用 model.predict(...) 调用模型 下面我们以 frugally-deep 主页 上的例子来说明如何使用。假设我们在 Python 中编写了模型 12345678910111213141516# create_model.pyimport numpy as npfrom tensorflow.keras.layers import Input, Densefrom tensorflow.keras.models import Modelinputs = Input(shape=(4,))x = Dense(5, activation='relu')(inputs)predictions = Dense(3, activation='softmax')(x)model = Model(inputs=inputs, outputs=predictions)model.compile(loss='categorical_crossentropy', optimizer='nadam')model.fit( np.asarray([[1, 2, 3, 4], [2, 3, 4, 5]]), np.asarray([[1, 0, 0], [0, 0, 1]]), epochs=10)model.save('keras_model.h5', include_optimizer=False) 运行 create_model.py 后，当前目录下生成了 keras_model.h5，接下来使用下面的命令进行转换 1python keras_export/convert_model.py keras_model.h5 fdeep_model.json 看到下面这些就是转换成功了，转换成功后，当前目录下会生成 fdeep_model.json，在 C++ 中读取 fdeep_model.json 就可以直接调用了。 12345678910111213141516Forward pass took 0.091729 s.Forward pass took 0.038896 s.Forward pass took 0.077791 s.Starting performance measurements.Forward pass took 0.037899 s.Forward pass took 0.037896 s.Forward pass took 0.043883 s.Forward pass took 0.038922 s.Forward pass took 0.042861 s.Forward pass took 0.04029220000000001 s on average.Converting model architecture.Converting model weights.Done converting model weights.Calculating model hash.Model conversion finished.writing fdeep_model.json 转换过程中，frugally-deep 会自动对模型进行测试，验证相同的输入下 ，模型在 Python 和 C++ 中的输出是否相同。若输出不同会直接报错，所以不必担心转换出错。 转换完成后，在 C++ 中进行调用 12345678910// main.cpp#include &lt;fdeep/fdeep.hpp&gt;int main()&#123; const auto model = fdeep::load_model(\"fdeep_model.json\"); const auto result = model.predict( &#123;fdeep::tensor(fdeep::tensor_shape(static_cast&lt;std::size_t&gt;(4)), &#123;1, 2, 3, 4&#125;)&#125;); std::cout &lt;&lt; fdeep::show_tensors(result) &lt;&lt; std::endl;&#125; 这时，以 Visual Studio 为例，编译器会报错 1fatal error C1083: 无法打开包括文件: “fdeep/fdeep.hpp”: No such file or directory 这是因为还没有添加附加包含目录，右键点击“解决方案资源管理器”中的项目名称，选择属性 -&gt; 配置属性 -&gt; C/C++ -&gt; 常规，在右侧的附加包含目录中填上 $(ProjectDir)include; 若使用的是 gcc 编译器，要在编译时加上参数 -Iinclude 再次运行 main.cpp，输出： 12345Loading json ... done. elapsed time: 0.009921 sBuilding model ... done. elapsed time: 0.018725 sRunning test 1 of 1 ... done. elapsed time: 0.003242 sLoading, constructing, testing of fdeep_model.json took 0.038064 s overall.[[[[[[[0.7297, 0.1624, 0.1078]]]]]]] 成功输出了结果，调用成功。另外，model.predict() 是线程安全的，可以直接在多个线程中调用。如果想在多 CPU 上并行预测，使用 model::predict_multi 就会自动在多 CPU 上执行 model.predict()。要注意的是，model::predict_multi 的并行是对多个输入数据的并行，并不是对一个数据的并行。 常见问题model.predict() 的数据类型frugally-deep 使用的数据类型是 fdeep::tensor，下面的例子说明了如何声明一个 fdeep::tensor 并初始化 1234// tensor的形状参数在fdeep::tensor_shape()中，0是初始化的值fdeep::tensor tensor_a(fdeep::tensor_shape(3, 8, 3), 0);// 将tensor_a[0][1][2]位置的值置1tensor_a.set(fdeep::internal::tensor_pos(0, 1, 2), 1); 有了 fdeep::tensor 我们可能会需要将其转化为 std::vector 进行后续的操作 12// 将tensor_a转为std::vectorconst std::vector&lt;float&gt; vec = *tensor_a.as_vector(); 除此之外，其他的方法可以参考官方 FAQ.md。要注意，frugally-deep 中必须采用 channel-last 的格式。 error C2653:使用 Visual Studio 2019 时可能会遇到这个问题 1error C2653: &apos;FOut&apos;: is not a class or namespace name 这是一个编译器 BUG，详见 Github issue ，目前已经在 16.5 Preview 2 版本中修复，解决方法是使用 Visual Studio 预览版或 Visual Studio 2017。 fdeep::model 没有默认构造函数当使用 fdeep::model 作为类的成员变量时，会遇到 fdeep::model 没有默认构造函数 的问题，这是作者刻意为之的，解决方法是使用std::unique_ptr&lt;fdeep::model&gt; 下面的例子说明了如何使用 1234567891011121314// neural_network.h#pragma once#include &lt;fdeep/fdeep.hpp&gt;class NeuralNetwork&#123;private: std::unique_ptr&lt;fdeep::model&gt; model;public: NeuralNetwork(); fdeep::tensors predict(fdeep::tensor&amp; feature_planes);&#125;; 123456789101112// neural_network.cpp#include \"neural_network.h\"NeuralNetwork::NeuralNetwork()&#123; this-&gt;model = std::make_unique&lt;fdeep::model&gt;(fdeep::load_model(\"fdeep_model.json\"));&#125;fdeep::tensors NeuralNetwork::predict(fdeep::tensor&amp; data)&#123; return this-&gt;model-&gt;predict(&#123; data &#125;);&#125; 运行速度比 Python 慢 100 倍这是因为编译器没有开优化。若使用 Visual Studio ，要把”Debug”模式改为”Release”模式。 gcc 要开 -O3 优化。修改后就正常了。参考FAQ.md 总结如果你需要在 C++ 中调用 model.predict() 且没有使用 GPU 的需求，frugally-deep 是一个很好的选择。 还想了解更多可以阅读官方的英文资料 frugally-deep 参考资料 https://github.com/Dobiasd/frugally-deep","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://iqhy.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://iqhy.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"C++","slug":"C","permalink":"https://iqhy.github.io/tags/C/"},{"name":"keras","slug":"keras","permalink":"https://iqhy.github.io/tags/keras/"}]},{"title":"Python 调用 C++","slug":"Python 调用 C++","date":"2020-02-28T07:56:01.000Z","updated":"2020-04-14T07:40:44.275Z","comments":true,"path":"posts/2020/0228155601/","link":"","permalink":"https://iqhy.github.io/posts/2020/0228155601/","excerpt":"Python 的代码优雅而实用，但是经常会遇到性能问题，这时可以使用 C/C++ 重写几个函数来解决，这样就同时兼顾了开发效率和性能。","text":"Python 的代码优雅而实用，但是经常会遇到性能问题，这时可以使用 C/C++ 重写几个函数来解决，这样就同时兼顾了开发效率和性能。 本文使用分为3个部分 安装 Cython (注意区别 CPython) Python 调用 C++ 函数 Python 调用 C++ 类 安装 Cython安装 Cython 最简单方法的是使用： pip install cython 或 conda install cython 与 Python 不同，Cython 编写的程序要先编译才能执行，因此，Cython 要求系统中有 C 编译器，在Windows 中使用 MinGW (gcc) 和 Visual Studio 的编译器均可。 Python 调用 C/C++ 函数编写一个 Python 函数以一个简单的函数为例，在 Python 中编写如下函数来计算 $tanh(x)$ 的值 1234567891011121314151617181920from random import randomfrom time import timee = 2.7182818284590452353602874713527def sinh(x): return (1 - (e ** (-2 * x))) / (2 * (e ** -x))def cosh(x): return (1 + (e ** (-2 * x))) / (2 * (e ** -x))def tanh(x): return sinh(x) / cosh(x)data = [random() for i in range(1000000)] # 生成随机数据start_time = time() # 调用1000000次tanh函数并统计时间result1 = list(map(tanh, data))end_time = time()print(end_time - start_time) 运行该程序需要 1.39 秒，将上述函数改写成 C++，将其保存在 mytanh.cpp 中 123456789101112131415161718#include &lt;cmath&gt;const double e = 2.7182818284590452353602874713527; double mysinh(double x)&#123; return (1 - pow(e, (-2 * x))) / (2 * pow(e, -x));&#125;double mycosh(double x)&#123; return (1 + pow(e, (-2 * x))) / (2 * pow(e, -x));&#125;double mytanh(double x)&#123; return mysinh(x) / mycosh(x);&#125; 由于sinh, cosh, tanh是 C++ 库函数，这里修改一下函数名。 在 Cython 中声明该函数新建一个fast_tanh.pyx 文件，.pyx 是 Cython 代码的后缀名，文件内容如下。 12345678# distutils: language = c++# cython: language_level = 3cdef extern from &quot;mytanh.cpp&quot;: double mytanh(double x) def fast_tanh(double x): return mytanh(x) 其中 12# distutils: language = c++# cython: language_level = 3 是用于配置编译器的特殊注释，分说明了使用的是 C++ 和 Python3 12cdef extern from &quot;mytanh.cpp&quot;: double mytanh(double x) Cython 使用 cdef extern from 来声明一个在 C++ 中实现的函数。上述代码声明了 mytanh 函数，使其可以在 Cython中使用。 在 Cython 中编写接口函数虽然 mytanh 现在可以在 Cython 中直接调用了，但 Python 并不能直接调用该函数，因此还要声明一个接口函数，命名为 fast_tahn。 12def fast_tanh(double x): return mytanh(x) 上述代码声明了一个接口函数，Cython 的语法与 Python 非常相似，若去掉形参中的 double 也是可行的，但若 Cython 知道参数的类型可以加速运行速度。Cython 支持大部分纯 Python 代码，因此可以在 Cython 中将 Python 的数据类型和 C++ 的数据类型相互转换，例如可以将 vector 转为 numpy array。若要使用 vector 类型，还需在开头加上 from libcpp.vector cimport vector。 编写 setup.pyfast_tanh.pyx 编写完后，需要编译后才能被 Python 调用，编译是通过 setup.py 进行的。 12345678910111213from distutils.core import setup, Extensionfrom Cython.Build import cythonizesetup(ext_modules=cythonize(Extension( 'fast_tanh', # 生成的模块名称 sources=['fast_tanh.pyx'], # 要编译的文件 language='c++', # 使用的语言 include_dirs=[], # gcc的-I参数 library_dirs=[], # gcc的-L参数 libraries=[], # gcc的-l参数 extra_compile_args=[], # 附加编译参数 extra_link_args=[], # 附加链接参数))) 其他参数可以根据需要添加，如果你暂时还不知道这些参数有什么用，那么可以先空着。将上述代码保存到 setup.py 后，运行如下命令即可编译 Cython 文件。 1python setup.py build_ext --inplace 需要注意，编译时的 Python 版本必须和调用时使用的 Python 版本相同。编译完成后，当前目录下会自动生成相应的 cpp 文件和 pyd 文件，在 Linux 上是 so 文件。 如果使用了 numpy 会在编译过程中看到警告： 1Warning Msg: Using deprecated NumPy API, disable it with #define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION 该警告可以忽略，因为 Cython 使用的是已经弃用的 Numpy API，不影响使用。 在 Python 中调用 fast_tanh 函数完成了编译的步骤后，fast_tanh在 Python 中就和一个普通的 Python 模块一样，可以使用 import 来导入 1from fast_tanh import fast_tanh # 从fast_tanh.pyx中导入fast_tanh函数 导入后，就可以在 Python 中像调用普通函数一样，直接使用 fast_tanh 函数了，完整代码如下，与之前的区别仅仅是把 tanh 替换成了 tanh，非常方便。 12345678910from random import randomfrom time import timefrom fast_tanh import fast_tanhdata = [random() for i in range(1000000)] # 生成随机数据start_time = time() # 计算并统计时间result = list(map(fast_tanh, data))end_time = time()print(end_time - start_time) # 输出运行时间 运行上述代码共需 0.18 秒，可以看到，仅仅替换了一个 tanh 函数后性能提升了近 8 倍。如果有其他更复杂的操作，可以提升几十上百倍的性能。 Python 调用 C/C++ 类编写一个 C++ 类知道如何调用一个 C/C++ 函数后，接下来继续调用一个 C/C++ 类。我们以一个简单的矩形类为例，假设我们在 C++ 中编写了一个矩形类。头文件 Rectangle.h 为： 123456789101112131415161718#ifndef RECTANGLE_H#define RECTANGLE_Hnamespace shapes &#123; class Rectangle &#123; public: int x0, y0, x1, y1; // 矩形对角线上的两个点坐标 Rectangle(); Rectangle(int x0, int y0, int x1, int y1); ~Rectangle(); int getArea(); void getSize(int* width, int* height); void move(int dx, int dy); &#125;;&#125;#endif Rectangle.cpp 中的实现为： 123456789101112131415161718192021222324252627282930#include &lt;iostream&gt;#include \"Rectangle.h\"namespace shapes &#123; // 构造函数 Rectangle::Rectangle () &#123;&#125; Rectangle::Rectangle (int x0, int y0, int x1, int y1) &#123; this-&gt;x0 = x0; this-&gt;y0 = y0; this-&gt;x1 = x1; this-&gt;y1 = y1; &#125; // 析构函数 Rectangle::~Rectangle () &#123;&#125; // 获取矩形面积 int Rectangle::getArea () &#123; return (this-&gt;x1 - this-&gt;x0) * (this-&gt;y1 - this-&gt;y0); &#125; // 获取矩形的边长 void Rectangle::getSize (int *width, int *height) &#123; (*width) = x1 - x0; (*height) = y1 - y0; &#125; // 移动矩形 void Rectangle::move (int dx, int dy) &#123; this-&gt;x0 += dx; this-&gt;y0 += dy; this-&gt;x1 += dx; this-&gt;y1 += dy; &#125;&#125; 在 Cython 中声明类接下来需要在 Cython 中编写一个接口。与前面调用 C++ 函数类似，使用 cdef extern from 来声明一个在 C++ 中实现的类： 1cdef extern from \"Rectangle.h\" namespace \"shapes\": 若没有命名空间，则使用： 1cdef extern from \"Rectangle.h\" 将声明放在 Rectangle.pxd 文件中，.pxd 文件相当于 C++ 的 .h 文件，专门用于声明： 1234567891011cdef extern from &quot;Rectangle.cpp&quot;: pass# 用cdef声明类cdef extern from &quot;Rectangle.h&quot; namespace &quot;shapes&quot;: cdef cppclass Rectangle: Rectangle() except + Rectangle(int, int, int, int) except + int x0, y0, x1, y1 int getArea() void getSize(int* width, int* height) void move(int, int) 由于 .h 文件中没有实现矩形类，还要使用 12cdef extern from &quot;Rectangle.cpp&quot;: pass 包含 Rectangle.cpp 中的代码 1cdef cppclass Rectangle: 声明了一个在 C++ 中定义的类，其他函数的声明与前面调用函数类似。在构造函数后加上 except + 可以使 Python 能够捕获到在构造函数中发生的异常，若不加 except +，则 Cython 不会处理构造函数中发生的异常。 在 Cython 中编写接口类与前面相同，虽然现在 C++ 中的类在 Cython 中可以直接访问了，但在 Python 中并不能访问。因此，我们还需要实现一个接口类，用于在 Python 中调用。注意，C++ 类的声明放在 .pxd 文件中, 接口类的实现放在 .pyx 中。PyRectangle.pyx为 : 1234567891011121314151617# distutils: language = c++from Rectangle cimport Rectangle# 接口类# Python可以直接访问接口类，接口类可以直接访问C++类cdef class PyRectangle: cdef Rectangle c_rect # 存储C++对象 def __cinit__(self, int x0, int y0, int x1, int y1): self.c_rect = Rectangle(x0, y0, x1, y1) def get_area(self): return self.c_rect.getArea() def get_size(self): cdef int width, height self.c_rect.getSize(&amp;width, &amp;height) return width, height def move(self, dx, dy): self.c_rect.move(dx, dy) 现在，PyRectangle 类就像普通的 Python 类一样可以直接在 Python 中调用了。 另外，Cython 也支持使用 new 创建 C++ 对象 12def __cinit__(self, int x0, int y0, int x1, int y1): self.c_rect = new Rectangle(x0, y0, x1, y1) 与 C++ 相同，使用了 new 就必须使用 delete 释放内存，否则会造成内存泄漏。 12def __dealloc__(self): # 析构函数 del self.c_rect # 释放内存 编译setup.py 内容如下 12345678910111213from distutils.core import setup, Extensionfrom Cython.Build import cythonizesetup(ext_modules=cythonize(Extension( 'PyRectangle', # 生成的模块名称 sources=['PyRectangle.pyx'], # 要编译的文件 language='c++', # 使用的语言 include_dirs=[], # gcc的-I参数 library_dirs=[], # gcc的-L参数 libraries=[], # gcc的-l参数 extra_compile_args=[], # 附加编译参数 extra_link_args=[], # 附加链接参数))) 使用 python setup.py build_ext --inplace 编译 在 Python 中调用接口类现在，PyRectangle 类就和普通的 Python 类一样，可以直接被 Python 调用 12345import PyRectanglex0, y0, x1, y1 = 1, 2, 3, 4rect = PyRectangle.PyRectangle(x0, y0, x1, y1)print(rect.get_area) 运行该程序，输出了矩形面积，调用成功。 总结通过 Cython 调用 C/C++ 的原理是： Python -&gt; Cython 接口 -&gt; C/C++ 访问 C++ 都是通过 Cython 接口完成的。 若还想了解更多，可以阅读 Cython 文档 参考资料 https://www.bookstack.cn/read/cython-doc-zh/README.md https://www.youtube.com/watch?v=D9RlT06a1EI&amp;t=45s","categories":[{"name":"Python","slug":"Python","permalink":"https://iqhy.github.io/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://iqhy.github.io/tags/Python/"},{"name":"C++","slug":"C","permalink":"https://iqhy.github.io/tags/C/"}]},{"title":"蒙特卡洛树搜索 MCTS 入门","slug":"蒙特卡洛树搜索 MCTS 入门","date":"2019-10-28T07:46:02.000Z","updated":"2020-03-02T02:36:01.090Z","comments":true,"path":"posts/2019/1028154602/","link":"","permalink":"https://iqhy.github.io/posts/2019/1028154602/","excerpt":"【内容简介】蒙特卡洛树搜索(Monte Carlo Tree Search) ，是一种寻找最优决策的方法。","text":"【内容简介】蒙特卡洛树搜索(Monte Carlo Tree Search) ，是一种寻找最优决策的方法。 蒙特卡洛树搜索(Monte Carlo Tree Search) 是一种寻找最优决策的方法，在AlphaGo中被运用，其主要分为四步：选择(Selection)，拓展(Expansion)，模拟(Simulation)，反向传播(Backpropagation)。 本文以井字棋为例对这一方法进行介绍。 基础知识节点在棋类问题中，MCTS 使用一个节点来表示一个游戏状态，换句话说，每一个节点都对应着井字棋中的一种情况。假设现在井字棋的棋盘上只有中间一个棋子，我们用一个节点表示这个游戏状态，这个节点就是下图中的根节点。这时，下一步棋有 8 种下法，所以对应的，这个根节点就有 8 个子节点(图中只画出了 3 个)。下完一步后，游戏还没有结束，继续按照刚才的方法，这些子节点又有子节点，所有的井字棋游戏状态都可以被这样表示，于是它们就构成了一个树。对于围棋或者其他更复杂的棋类也是一样，只不过这个树会更大、更复杂。蒙特卡洛树搜索就是要在这样一个树中搜索出最可能获胜下一步，即搜索在当前局面下，在哪个位置下棋最有可能获胜。 节点的两个属性在蒙特卡洛树搜索中，我们将节点记作 $v$，在搜索过程中需要记录节点的访问次数和累计奖励，它们的表示符号如下： $N(v)$：节点 $v$ 的访问次数，节点在搜索过程中被访问多少次，该值就是多少。 $Q(v)$：节点 $v$ 的累计奖励，即节点在反向传播过程中获得的所有奖励(reward)求和。 所谓的奖励(reward)是一个数值，游戏结束时若获胜，奖励为 1，若失败，奖励为 0。 搜索过程那么，给定当前游戏状态，如何获得下一步的最佳下法呢？对于井字棋来说，当然可以在整个决策树中遍历所有可能性，直接找出最优策略。但若换成围棋等复杂的棋类，遍历的方法是显然不可行的，这时就需要在决策树中有选择地访问节点，并根据现有的有限信息做出最优决策。 在介绍下面的搜索过程之前，我们首先要知道：蒙特卡洛树搜索搜的是什么？换句话说，假如我们先把 MCTS 看成一个黑盒子，那么它的输入和输出分别是什么？ 输入：一个游戏状态 输出：下一步下棋的位置 也就是说，给 MCTS 一个棋局，它就告诉你下一步该怎么走。知道了输入输出分别是什么后，我们再来看看从输入到输出这中间，MCTS 到底做了什么。 选择(Selection)由于遍历的方法不可行，MCTS 需要有选择地访问节点，这就是选择阶段。从根节点(就是输入)出发，根据一定的策略，向下选择一个要访问的节点，若被选择的节点未被访问过，则执行扩展；若被选择的节点已被访问，则继续向下选择节点，直到遇见未被访问的节点并执行扩展，或遇见终止节点(游戏结束)，无需执行扩展，而直接执行反向传播。扩展和反向传播是为了积累在选择中获得的信息。 选择的策略由该公式确定，对当前节点的每个子节点计算如下公式，并选择计算结果最大的节点。$$\\underset{v’\\in ,,\\text{children of }v}{arg\\max}\\frac{Q\\left( v’ \\right)}{N\\left( v’ \\right)}+c\\sqrt{\\frac{\\text{2}\\ln N\\left( v \\right)}{N\\left( v’ \\right)}}$$其中， $v$ 表示父节点，$v’$ 表示子节点。$c$ 是一个常数，用于权衡探索 (Exploration) 与利用 (Exploitation)。探索是指：其他没有访问过的节点可能会获得更高的奖励，所以要访问这些节点；而利用是指：多访问在当前已知信息下，平均奖励最高的节点，因为大概率有好结果。$c$ 越大，就越偏向于探索；$c$ 越小，就越偏向于利用。 扩展 (Expansion)MCTS 在搜索的过程中是有选择地访问节点，并把所有访问过的节点构建成一个树。扩展非常简单，就是把选择步骤中遇到的未访问节点添加到现有的树中。 模拟 (Simulation)模拟是一个粗略获取信息的过程。从被扩展的节点开始，对游戏进行模拟，也就是在棋盘上随机下棋，直到游戏结束。若此时游戏胜利，则奖励 (Reward) 为 $1$；若游戏失败，奖励为 $0$。这里的奖励将会在反向传播中用到。 注：在其他应用中，奖励也可是其他值。 反向传播 (Backpropagation)反向传播是将在模拟中得到的信息更新的过程。 将奖励记作 $R$，对当前节点，及其所有父节点 $v$，都执行以下操作。即，更新访问次数，对奖励进行累加。$$N(v)=N(v)+1 \\\\Q(v)=Q(v)+R$$我们再回头看看选择步骤中的公式$$\\underset{v’\\in ,,\\text{children of }v}{arg\\max}\\frac{Q\\left( v’ \\right)}{N\\left( v’ \\right)}+c\\sqrt{\\frac{\\text{2}\\ln N\\left( v \\right)}{N\\left( v’ \\right)}}$$可以看到，式中第一项其实就是该节点在前面的过程中获得的平均奖励，自然该值越大，选择该节点就越有可能获胜。那么为什么要加上第二项呢？这就涉及到探索与利用的权衡。 我们不能只选择已访问过的节点中平均奖励最大的节点，一些访问次数较少的、甚至没有访问过的节点它们可能获得比已探索的节点更丰厚的回报，因此也要适当地在未知的节点进行探索。这就是第二项的含义，当该节点访问次数占父节点次数的比例越小时，该值越大，代表我们越要在此节点进行探索。于是就不难理解$c$用于是权衡探索与利用的常数了。 这就是上限置信区间算法 (Upper Confidence Bound )，简称UCT算法。 搜索过程展示MCTS 其实就是一个不断重复上述四个步骤的过程。 看完了这四个步骤，我们再来看一张动图帮助理解。图中节点内数字表示 $Q(v)/N(v)$ 搜索结束MCTS 的整个过程就是这样，那么什么时候结束呢？一般设置以下两个终止条件。 设置最大根节点搜索次数，达到该次数后结束搜索。 设置最大搜索时间，超过时间后结束搜索。 结束后，就输出当前状态下，下一步下棋的位置。 选择最佳节点搜索结束后，如何选择下一步下棋的位置呢？ 不是选择 $Q$ 最大的节点，也不是选择平均奖励最大的节点，而是选择访问次数最多的节点。这样，就得到了当前游戏状态(根节点)下的一个选择。或者，也可以将访问次数归一化，作为下一步的概率。 如果下一步还要进行决策，则又要将下一步的状态作为根节点，重新执行 MCTS，并选择访问次数最多的节点作为下一步的策略。(上一步的搜索结果可以保留) 以上只是 MCTS 的简单介绍，想更详细的了解 MCTS 可以参考论文A Survey of Monte Carlo Tree Search Methods 另外，Github 上也已经有 MCTS 的 Python 实现源码 https://github.com/pbsinclair42/MCTS。文档比较全，有详细的例子。","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://iqhy.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"mcts","slug":"mcts","permalink":"https://iqhy.github.io/tags/mcts/"}]}]}